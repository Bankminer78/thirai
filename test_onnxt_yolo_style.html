<!doctype html>
<meta charset="utf-8" />
<title>SDXL VAE Decoder (YOLO Style WebGPU)</title>
<style>
  body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; max-width: 920px; margin: 24px auto; }
  .row { display: flex; gap: 16px; align-items: center; flex-wrap: wrap; }
  #cv { border: 1px solid #ccc; border-radius: 6px; image-rendering: auto; }
  #log { white-space: pre-wrap; background: #111; color: #ddd; padding: 12px; border-radius: 8px; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; font-size: 12px; max-height: 400px; overflow-y: scroll; }
  label { font-size: 14px; }
  button { margin: 5px; padding: 8px 16px; background: #007acc; color: white; border: none; border-radius: 4px; cursor: pointer; }
  button:hover { background: #005a9e; }
  button:disabled { background: #ccc; cursor: not-allowed; }
</style>

<h1>SDXL VAE Decoder (YOLO Style WebGPU)</h1>

<div class="row">
  <label>Model URL:
    <input id="modelUrl" size="42" value="sdxl_vae_decoder_fp32.onnx"/>
  </label>
  <button id="loadBtn">Load Model</button>
</div>

<div class="row">
  <label>Upload latent file:
    <input type="file" id="fileInput" accept=".bin" />
  </label>
  <button id="processBtn" disabled>Process Latent</button>
  <button id="benchmarkBtn" disabled>Benchmark (3x)</button>
</div>

<canvas id="cv" width="384" height="384"></canvas>
<button id="downloadBtn" style="display:none;">Download PNG</button>

<h3>Log</h3>
<pre id="log"></pre>

<script type="module">
// YOLO-style WebGPU ONNX Runtime implementation
let ort;

// Load ONNX Runtime WebGPU
try {
  // Try ES6 import first
  ort = await import('https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1/webgpu');
  console.log('‚úÖ Loaded via ES6 import');
} catch (e) {
  console.log('‚ùå ES6 import failed, trying script load...');
  // Fallback to script loading
  await new Promise((resolve, reject) => {
    const script = document.createElement('script');
    script.src = './ort.webgpu.1.20.1.min.js';
    script.onload = () => {
      ort = window.ort;
      resolve();
    };
    script.onerror = reject;
    document.head.appendChild(script);
  });
  console.log('‚úÖ Loaded via local script');
}

let session = null;
let selectedFile = null;

const logEl = document.getElementById('log');
const cv = document.getElementById('cv');
const ctx = cv.getContext('2d');

function log(...args) {
  const msg = args.join(' ') + '\n';
  logEl.textContent += msg;
  logEl.scrollTop = logEl.scrollHeight;
  console.log(...args);
}

function setCanvasSize(w, h) {
  cv.width = w;
  cv.height = h;
}

function guessHWFromLen(nelems, channels = 4) {
  const spatial = nelems / channels;
  const side = Math.round(Math.sqrt(spatial));
  if (side * side * channels !== nelems) return null;
  return { H8: side, W8: side, H: side * 8, W: side * 8 };
}

async function loadSession() {
  const modelUrl = document.getElementById('modelUrl').value.trim();
  
  try {
    log('üöÄ Loading ONNX Runtime WebGPU (YOLO style)...');
    
    // YOLO-style WASM path configuration
    ort.env.wasm.wasmPaths = './';
    
    log('üîÑ Creating WebGPU session...');
    const sessionStart = performance.now();
    
    // Simple session creation like YOLO
    session = await ort.InferenceSession.create(modelUrl, {
      executionProviders: ['webgpu']
    });
    
    const sessionTime = performance.now() - sessionStart;
    log(`‚úÖ Session created in ${sessionTime.toFixed(2)}ms`);
    
    // YOLO-style warmup with proper disposal
    log('üî• Warming up session...');
    const warmupStart = performance.now();
    
    const dummyTensor = new ort.Tensor('float32', new Float32Array(4 * 48 * 48), [1, 4, 48, 48]);
    const { y: warmupOutput } = await session.run({ z_scaled: dummyTensor });
    
    // Proper tensor disposal (YOLO pattern)
    dummyTensor.dispose();
    warmupOutput.dispose();
    
    const warmupTime = performance.now() - warmupStart;
    log(`‚úÖ Warmup completed in ${warmupTime.toFixed(2)}ms`);
    log('üéâ WebGPU VAE decoder ready!');
    
    // Enable UI
    document.getElementById('processBtn').disabled = !selectedFile;
    document.getElementById('benchmarkBtn').disabled = !selectedFile;
    
  } catch (error) {
    log(`‚ùå Session creation failed: ${error.message}`);
    throw error;
  }
}

async function decodeLatent(buffer) {
  if (!session) throw new Error('‚ùå Model not loaded');
  
  const totalStart = performance.now();
  
  // Process FP16 buffer (assume it's always FP16 from your generator)
  log('üîÑ Processing FP16 latent...');
  const u16 = new Uint16Array(buffer);
  const guess = guessHWFromLen(u16.length);
  
  let H8, W8, H, W;
  if (guess) {
    ({ H8, W8, H, W } = guess);
    log(`üéØ Detected: ${H8}√ó${W8} latent ‚Üí ${H}√ó${W} image`);
  } else {
    H = W = 384; H8 = 48; W8 = 48;
    log(`üéØ Default: ${H8}√ó${W8} latent ‚Üí ${H}√ó${W} image`);
  }
  
  if (u16.length !== 4 * H8 * W8) {
    throw new Error(`‚ùå Size mismatch: got ${u16.length}, expected ${4 * H8 * W8}`);
  }
  
  // Fast FP16 ‚Üí FP32 conversion
  const convStart = performance.now();
  const f32Array = new Float32Array(u16.length);
  for (let i = 0; i < u16.length; i++) {
    const bits = u16[i];
    if (bits === 0) {
      f32Array[i] = 0.0;
    } else {
      const signed = (bits << 16) >> 16;
      f32Array[i] = signed / 32768.0;
    }
  }
  const convTime = performance.now() - convStart;
  
  // Create input tensor
  const inputTensor = new ort.Tensor('float32', f32Array, [1, 4, H8, W8]);
  
  // WebGPU inference (YOLO style)
  log(`‚ö° Running WebGPU inference...`);
  const inferenceStart = performance.now();
  const { y: outputTensor } = await session.run({ z_scaled: inputTensor });
  const inferenceTime = performance.now() - inferenceStart;
  
  // Performance analysis
  if (inferenceTime > 2000) {
    log(`üêå SLOW! ${inferenceTime.toFixed(2)}ms - likely CPU fallback`);
  } else if (inferenceTime > 500) {
    log(`‚ö†Ô∏è MODERATE: ${inferenceTime.toFixed(2)}ms - WebGPU may have issues`);
  } else {
    log(`üöÄ FAST! ${inferenceTime.toFixed(2)}ms - WebGPU working well`);
  }
  
  // Process output (YOLO style with proper disposal)
  const pixelStart = performance.now();
  const outputData = outputTensor.data;
  const plane = H * W;
  
  // Create image data efficiently
  const imageData = ctx.createImageData(W, H);
  const imgData = imageData.data;
  
  for (let px = 0, i = 0; px < plane; px++, i += 4) {
    const r = (outputData[px] + 1) * 127.5;
    const g = (outputData[px + plane] + 1) * 127.5;
    const b = (outputData[px + plane * 2] + 1) * 127.5;
    
    imgData[i] = r < 0 ? 0 : r > 255 ? 255 : r | 0;
    imgData[i + 1] = g < 0 ? 0 : g > 255 ? 255 : g | 0;
    imgData[i + 2] = b < 0 ? 0 : b > 255 ? 255 : b | 0;
    imgData[i + 3] = 255;
  }
  
  setCanvasSize(W, H);
  ctx.putImageData(imageData, 0, 0);
  document.getElementById('downloadBtn').style.display = 'inline-block';
  
  const pixelTime = performance.now() - pixelStart;
  const totalTime = performance.now() - totalStart;
  
  // CRITICAL: Proper tensor disposal (YOLO pattern)
  inputTensor.dispose();
  outputTensor.dispose();
  
  log(`‚úÖ Complete! Conv: ${convTime.toFixed(2)}ms | Inference: ${inferenceTime.toFixed(2)}ms | Pixels: ${pixelTime.toFixed(2)}ms | Total: ${totalTime.toFixed(2)}ms`);
}

// Event Handlers
document.getElementById('loadBtn').addEventListener('click', () => {
  loadSession().catch(e => log('‚ùå Load error:', e.message));
});

document.getElementById('fileInput').addEventListener('change', e => {
  selectedFile = e.target.files[0] || null;
  const hasSession = !!session;
  document.getElementById('processBtn').disabled = !selectedFile || !hasSession;
  document.getElementById('benchmarkBtn').disabled = !selectedFile || !hasSession;
  if (selectedFile) {
    log(`üìÅ Selected: ${selectedFile.name} (${selectedFile.size} bytes)`);
  }
});

document.getElementById('processBtn').addEventListener('click', async () => {
  if (!selectedFile || !session) return;
  
  try {
    const buf = await selectedFile.arrayBuffer();
    await decodeLatent(buf);
  } catch (err) {
    log('‚ùå Processing error:', err.message);
  }
});

document.getElementById('benchmarkBtn').addEventListener('click', async () => {
  if (!selectedFile || !session) return;
  
  try {
    log('üèÅ Starting 3-run benchmark...');
    const buf = await selectedFile.arrayBuffer();
    const times = [];
    
    for (let i = 0; i < 3; i++) {
      log(`üèÉ Run ${i + 1}/3...`);
      const start = performance.now();
      await decodeLatent(buf);
      const time = performance.now() - start;
      times.push(time);
    }
    
    const avg = times.reduce((a, b) => a + b, 0) / times.length;
    const min = Math.min(...times);
    const max = Math.max(...times);
    
    log('üèÜ BENCHMARK RESULTS:');
    log(`   Average: ${avg.toFixed(2)}ms`);
    log(`   Best: ${min.toFixed(2)}ms`);
    log(`   Worst: ${max.toFixed(2)}ms`);
    
  } catch (err) {
    log('‚ùå Benchmark error:', err.message);
  }
});

document.getElementById('downloadBtn').addEventListener('click', () => {
  const a = document.createElement('a');
  a.download = 'decoded_image.png';
  a.href = cv.toDataURL('image/png');
  a.click();
  log('üì• PNG downloaded');
});

// Auto-load
log('üé¨ Starting YOLO-style WebGPU VAE decoder...');
loadSession().catch(e => log('‚ùå Auto-load failed:', e.message));

</script>