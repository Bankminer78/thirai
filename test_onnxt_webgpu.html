<!doctype html>
<meta charset="utf-8" />
<title>SDXL VAE Decoder (WebGPU Only) ‚Äî Upload Latent</title>
<style>
  body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; max-width: 920px; margin: 24px auto; }
  .row { display: flex; gap: 16px; align-items: center; flex-wrap: wrap; }
  #cv { border: 1px solid #ccc; border-radius: 6px; image-rendering: auto; }
  #log { white-space: pre-wrap; background: #111; color: #ddd; padding: 12px; border-radius: 8px; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; font-size: 12px; }
  label { font-size: 14px; }
  #downloadBtn, #processBtn, #benchmarkBtn { margin-top: 10px; padding: 8px 16px; background: #007acc; color: white; border: none; border-radius: 4px; cursor: pointer; }
  #downloadBtn:hover, #processBtn:hover, #benchmarkBtn:hover { background: #005a9e; }
  #downloadBtn:disabled, #processBtn:disabled, #benchmarkBtn:disabled { background: #ccc; cursor: not-allowed; }
</style>

<h1>SDXL VAE Decoder (WebGPU Only) ‚Äî Upload Latent</h1>

<div class="row">
  <label>Model URL:
    <input id="modelUrl" size="42" value="sdxl_vae_decoder_fp32.onnx"/>
  </label>
  <label>Latent dtype:
    <select id="dtype">
      <option value="float16" selected>float16 (Uint16 blob)</option>
      <option value="float32">float32</option>
    </select>
  </label>
  <label>Target res (H=W):
    <input id="res" type="number" value="384" min="64" step="8" style="width:80px"/>
  </label>
  <button id="loadBtn">Load Model (WebGPU)</button>
</div>

<div class="row">
  <label>Upload latent file:
    <input type="file" id="fileInput" accept=".bin" />
  </label>
  <button id="processBtn" disabled>Process Latent</button>
  <button id="benchmarkBtn" disabled>Benchmark (5x)</button>
  <button id="debugBtn">Debug WebGPU</button>
</div>
<canvas id="cv" width="384" height="384"></canvas>
<button id="downloadBtn" style="display:none;">Download PNG</button>

<h3>Log</h3>
<pre id="log"></pre>

<script type="module">
/** WebGPU-Only ONNX Runtime VAE Decoder **/
let session = null;
let IS = null, ENV = null, Tensor = null;

const logEl = document.getElementById('log');
const cv = document.getElementById('cv');
let ctx = null;

function log(...args){ 
  logEl.textContent += args.join(' ') + '\n'; 
  console.log(...args); 
}

function setCanvasSize(w, h){
  if (cv.width !== w || cv.height !== h) { 
    cv.width = w; 
    cv.height = h; 
  }
  if (!ctx) ctx = cv.getContext('2d');
}

function guessHWFromLen(nelems, channels=4){
  const spatial = nelems / channels;
  const side = Math.round(Math.sqrt(spatial));
  if (side * side * channels !== nelems) return null;
  return { H8: side, W8: side, H: side*8, W: side*8 };
}

// WebGPU-only loader
async function loadOrtWebGPU() {
  // Strict WebGPU requirements check
  if (!('gpu' in navigator)) {
    throw new Error('‚ùå WebGPU not available in this browser');
  }
  
  log('üîç Checking WebGPU adapter...');
  const adapter = await navigator.gpu.requestAdapter();
  if (!adapter) {
    throw new Error('‚ùå No WebGPU adapter found');
  }
  
  // Check adapter compatibility more carefully
  log('üîç Testing adapter compatibility...');
  try {
    const device = await adapter.requestDevice();
    device.destroy(); // Clean up immediately
    log('‚úÖ WebGPU adapter compatible');
  } catch (e) {
    throw new Error(`‚ùå WebGPU adapter incompatible: ${e.message}`);
  }
  
  // Try compatible ONNX Runtime versions (newer versions may have compatibility issues)
  const scriptSources = [
    'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.16.3/dist/ort.webgpu.min.js',
    'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.17.1/dist/ort.webgpu.min.js',
    'https://unpkg.com/onnxruntime-web@1.16.3/dist/ort.webgpu.min.js',
    'https://unpkg.com/onnxruntime-web@1.17.1/dist/ort.webgpu.min.js',
    './ort.webgpu.min.js'
  ];
  
  for (const src of scriptSources) {
    try {
      log(`üîÑ Trying script: ${src}`);
      await loadScript(src);
      if (window.ort && window.ort.InferenceSession && window.ort.env) {
        log(`‚úÖ WebGPU ONNX Runtime loaded via script`);
        return { IS: window.ort.InferenceSession, ENV: window.ort.env, Tensor: window.ort.Tensor, source: 'script' };
      }
    } catch(e) { 
      log(`‚ùå Script failed: ${e.message}`); 
    }
  }
  
  throw new Error('‚ùå Unable to load WebGPU ONNX Runtime from any source');
}

function loadScript(src){
  return new Promise((resolve, reject) => {
    const s = document.createElement('script');
    s.src = src; 
    s.async = true; 
    s.crossOrigin = 'anonymous';
    s.onload = resolve; 
    s.onerror = () => reject(new Error('Script load failed: ' + src));
    document.head.appendChild(s);
  });
}

async function loadSession(){
  const modelUrl = document.getElementById('modelUrl').value.trim();
  
  log('üöÄ Loading WebGPU-only ONNX Runtime...');
  
  try {
    // Load WebGPU ONNX Runtime
    const mod = await loadOrtWebGPU();
    IS = mod.IS; 
    ENV = mod.ENV; 
    Tensor = mod.Tensor;
    
    log(`üì¶ ONNX Runtime source: ${mod.source}`);
    
    // Configure WebGPU environment
    if (ENV?.webgpu) {
      log('üîß Initializing WebGPU environment...');
      if (ENV.webgpu.init) {
        try {
          await ENV.webgpu.init();
          log('‚úÖ WebGPU backend initialized');
        } catch (e) {
          log('‚ö†Ô∏è WebGPU init warning:', e.message);
        }
      }
      ENV.webgpu.validateInputContent = false; // Performance optimization
      log('‚úÖ WebGPU environment configured');
    } else {
      log('‚ö†Ô∏è No ENV.webgpu found - may affect performance');
    }
    
    // Set global log level
    if (ENV) {
      ENV.logLevel = 'warning';
    }
    
    log(`üîÑ Creating inference session: ${modelUrl}`);
    const sessionStart = performance.now();
    
    // Create WebGPU session with minimal options for compatibility
    const sessionOptions = { 
      executionProviders: ['webgpu']
      // Remove advanced options that might cause compatibility issues
    };
    
    log('üîß Session options:', JSON.stringify(sessionOptions));
    const sessionPromise = IS.create(modelUrl, sessionOptions);
    
    // Add timeout to prevent hanging
    const timeoutPromise = new Promise((_, reject) => {
      setTimeout(() => reject(new Error('Session creation timed out (30s)')), 30000);
    });
    
    session = await Promise.race([sessionPromise, timeoutPromise]);
    
    const sessionTime = performance.now() - sessionStart;
    log(`‚úÖ Session created in ${sessionTime.toFixed(2)}ms`);
    
    // Verify we're actually using WebGPU (different ONNX versions expose this differently)
    const provider = session.executionProvider || session.executionProviders?.[0] || 'unknown';
    log(`üéØ Detected provider: ${provider}`);
    
    // Be more lenient - if we got this far with WebGPU config, assume it's working
    if (provider !== 'webgpu' && provider !== 'unknown') {
      log(`‚ö†Ô∏è Warning: Expected WebGPU but got ${provider} - may still work`);
    } else if (provider === 'webgpu') {
      log(`‚úÖ Confirmed WebGPU provider active`);
    } else {
      log(`ü§û Provider detection unclear but proceeding (WebGPU requested)`);
    }
    
    // Warm-up the WebGPU session with timeout
    log('üî• Warming up WebGPU session...');
    const warmupStart = performance.now();
    const dummyTensor = new Tensor('float32', new Float32Array(4*48*48), [1,4,48,48]);
    
    const warmupPromise = session.run({ z_scaled: dummyTensor });
    const warmupTimeoutPromise = new Promise((_, reject) => {
      setTimeout(() => reject(new Error('Warmup timed out (15s)')), 15000);
    });
    
    await Promise.race([warmupPromise, warmupTimeoutPromise]);
    const warmupTime = performance.now() - warmupStart;
    log(`‚úÖ Warmup completed in ${warmupTime.toFixed(2)}ms`);
    
    log('üéâ WebGPU VAE decoder ready!');
    
  } catch (error) {
    log(`‚ùå Failed to load WebGPU session: ${error.message}`);
    throw error;
  }
}

// Ultra-fast decode with WebGPU optimizations
const cache = { rgba: null, W: 0, H: 0 };

async function decodeLatent(buffer){
  if (!session) throw new Error('‚ùå Model not loaded');
  
  const dtype = document.getElementById('dtype').value;
  const targetRes = parseInt(document.getElementById('res').value, 10) || 384;
  
  log(`üîÑ Processing ${dtype} latent (${buffer.byteLength} bytes)...`);
  
  let H, W, H8, W8, tensor;
  const prepStart = performance.now();
  
  if (dtype === 'float16') {
    const u16 = new Uint16Array(buffer);
    const guess = guessHWFromLen(u16.length);
    if (guess) { 
      ({H8,W8,H,W} = guess); 
      log(`üéØ Auto-detected: ${H8}√ó${W8} latent ‚Üí ${H}√ó${W} image`);
    } else { 
      H=W=targetRes; H8=H/8|0; W8=W/8|0; 
      log(`üéØ Using target: ${H8}√ó${W8} latent ‚Üí ${H}√ó${W} image`);
    }
    
    if (u16.length !== 4*H8*W8) {
      throw new Error(`‚ùå Latent size mismatch: got ${u16.length}, expected ${4*H8*W8}`);
    }
    
    // Convert FP16 to FP32 efficiently for model compatibility
    log('üîÑ Converting FP16‚ÜíFP32 for model...');
    const convStart = performance.now();
    const f32Array = new Float32Array(u16.length);
    for (let i = 0; i < u16.length; i++) {
      // Fast FP16 to FP32 approximation
      const bits = u16[i];
      if (bits === 0) {
        f32Array[i] = 0.0;
      } else {
        // Simple conversion: treat as signed 16-bit and normalize
        const signed = (bits << 16) >> 16;
        f32Array[i] = signed / 32768.0;
      }
    }
    const convTime = performance.now() - convStart;
    log(`‚úÖ FP16‚ÜíFP32 conversion complete (${convTime.toFixed(2)}ms)`);
    
    const tensorStart = performance.now();
    tensor = new Tensor('float32', f32Array, [1,4,H8,W8]);
    const tensorTime = performance.now() - tensorStart;
    log(`‚úÖ Tensor created (${tensorTime.toFixed(2)}ms)`);
  } else {
    const f32 = new Float32Array(buffer);
    const guess = guessHWFromLen(f32.length);
    if (guess) { 
      ({H8,W8,H,W} = guess); 
    } else { 
      H=W=targetRes; H8=H/8|0; W8=W/8|0; 
    }
    
    if (f32.length !== 4*H8*W8) {
      throw new Error(`‚ùå Latent size mismatch: got ${f32.length}, expected ${4*H8*W8}`);
    }
    
    tensor = new Tensor('float32', f32, [1,4,H8,W8]);
  }
  
  const prepTime = performance.now() - prepStart;
  
  // WebGPU inference with performance analysis
  log('‚ö° Running WebGPU inference...');
  const inferenceStart = performance.now();
  const out = await session.run({ z_scaled: tensor });
  const inferenceTime = performance.now() - inferenceStart;
  
  log(`üöÄ Inference completed in ${inferenceTime.toFixed(2)}ms`);
  
  // Performance analysis
  const expectedWebGPUTime = 100; // WebGPU should be ~50-200ms for this model
  const expectedCPUTime = 3000; // CPU would be 3-10 seconds
  
  if (inferenceTime > expectedCPUTime * 0.8) {
    log(`üêå SLOW! ${inferenceTime.toFixed(2)}ms suggests CPU fallback - WebGPU may not be working`);
  } else if (inferenceTime > expectedWebGPUTime * 5) {
    log(`‚ö†Ô∏è SLOWER than expected (${inferenceTime.toFixed(2)}ms) - possible WebGPU inefficiency`);
  } else {
    log(`üöÄ FAST! ${inferenceTime.toFixed(2)}ms suggests WebGPU is working well`);
  }
  
  // Fast pixel processing
  const pixelStart = performance.now();
  const y = out.y;
  const plane = H * W;
  const data = y.data;
  
  // Reuse RGBA buffer for performance
  if (cache.W !== W || cache.H !== H) {
    cache.W = W; 
    cache.H = H;
    cache.rgba = new Uint8ClampedArray(plane * 4);
  }
  const rgba = cache.rgba;
  
  // Ultra-fast planar RGB ‚Üí interleaved RGBA conversion
  for (let px = 0, i = 0; px < plane; px++, i += 4) {
    const r = (data[px] + 1) * 127.5;
    const g = (data[px + plane] + 1) * 127.5;
    const b = (data[px + plane * 2] + 1) * 127.5;
    
    rgba[i] = r < 0 ? 0 : r > 255 ? 255 : r | 0;
    rgba[i + 1] = g < 0 ? 0 : g > 255 ? 255 : g | 0;
    rgba[i + 2] = b < 0 ? 0 : b > 255 ? 255 : b | 0;
    rgba[i + 3] = 255;
  }
  
  const pixelTime = performance.now() - pixelStart;
  
  // Fast canvas rendering
  setCanvasSize(W, H);
  const imgData = new ImageData(rgba, W, H);
  ctx.putImageData(imgData, 0, 0);
  
  const totalTime = prepTime + inferenceTime + pixelTime;
  log(`‚úÖ Complete! Prep: ${prepTime.toFixed(2)}ms | Inference: ${inferenceTime.toFixed(2)}ms | Pixels: ${pixelTime.toFixed(2)}ms | Total: ${totalTime.toFixed(2)}ms`);
}

// UI Event Handlers
const fileInput = document.getElementById('fileInput');
const processBtn = document.getElementById('processBtn');
const benchmarkBtn = document.getElementById('benchmarkBtn');
const downloadBtn = document.getElementById('downloadBtn');
const loadBtn = document.getElementById('loadBtn');
const debugBtn = document.getElementById('debugBtn');

let selectedFile = null;

loadBtn.addEventListener('click', () => {
  loadSession().catch(e => log('‚ùå Model load error:', e.message || e));
});

fileInput.addEventListener('change', e => {
  selectedFile = e.target.files[0] || null;
  processBtn.disabled = !selectedFile || !session;
  benchmarkBtn.disabled = !selectedFile || !session;
  if (selectedFile) {
    log(`üìÅ Selected: ${selectedFile.name} (${selectedFile.size} bytes)`);
  }
});

processBtn.addEventListener('click', async () => {
  if (!selectedFile || !session) return;
  
  try {
    processBtn.disabled = true;
    processBtn.textContent = 'Processing...';
    
    const buf = await selectedFile.arrayBuffer();
    await decodeLatent(buf);
    downloadBtn.style.display = 'inline-block';
    
  } catch (err) {
    log('‚ùå Processing error:', err.message);
  } finally {
    processBtn.disabled = false;
    processBtn.textContent = 'Process Latent';
  }
});

benchmarkBtn.addEventListener('click', async () => {
  if (!selectedFile || !session) return;
  
  try {
    benchmarkBtn.disabled = true;
    benchmarkBtn.textContent = 'Benchmarking...';
    
    log('üèÅ Starting 5-run benchmark...');
    const buf = await selectedFile.arrayBuffer();
    const times = [];
    
    for (let i = 0; i < 5; i++) {
      log(`üèÉ Run ${i + 1}/5...`);
      const start = performance.now();
      await decodeLatent(buf);
      const time = performance.now() - start;
      times.push(time);
    }
    
    const avg = times.reduce((a,b) => a+b, 0) / times.length;
    const min = Math.min(...times);
    const max = Math.max(...times);
    
    const currentProvider = session.executionProvider || session.executionProviders?.[0] || 'unknown';
    log('üèÜ BENCHMARK RESULTS:');
    log(`   Average: ${avg.toFixed(2)}ms`);
    log(`   Best: ${min.toFixed(2)}ms`);
    log(`   Worst: ${max.toFixed(2)}ms`);
    log(`   Provider: ${currentProvider}`);
    
  } catch (err) {
    log('‚ùå Benchmark error:', err.message);
  } finally {
    benchmarkBtn.disabled = false;
    benchmarkBtn.textContent = 'Benchmark (5x)';
  }
});

downloadBtn.addEventListener('click', () => {
  const a = document.createElement('a');
  a.download = 'decoded_image.png';
  a.href = cv.toDataURL('image/png');
  a.click();
  log('üì• PNG downloaded');
});

debugBtn.addEventListener('click', async () => {
  log('üîç WebGPU Debug Information:');
  
  // GPU Info
  if (navigator.gpu) {
    const adapter = await navigator.gpu.requestAdapter();
    if (adapter) {
      log(`GPU Adapter: Available`);
      try {
        const device = await adapter.requestDevice();
        log(`GPU Device: Created successfully`);
        device.destroy();
      } catch (e) {
        log(`GPU Device: Failed - ${e.message}`);
      }
    }
  }
  
  // Session Info
  if (session) {
    const provider = session.executionProvider || session.executionProviders?.[0] || 'unknown';
    log(`Session Provider: ${provider}`);
    log(`Session Available: Yes`);
    
    // Quick performance test
    log('üèÉ Quick WebGPU test...');
    const testTensor = new Tensor('float32', new Float32Array(4*48*48), [1,4,48,48]);
    const start = performance.now();
    try {
      await session.run({ z_scaled: testTensor });
      const time = performance.now() - start;
      log(`‚ö° Test inference: ${time.toFixed(2)}ms`);
      if (time > 2000) {
        log('üêå SLOW - likely using CPU instead of WebGPU');
      } else if (time > 500) {
        log('‚ö†Ô∏è MODERATE - WebGPU may have issues');
      } else {
        log('üöÄ FAST - WebGPU working well');
      }
    } catch (e) {
      log(`‚ùå Test inference failed: ${e.message}`);
    }
  } else {
    log('Session: Not loaded');
  }
});

// Auto-load on startup
log('üé¨ Starting WebGPU-only VAE decoder...');
loadSession().catch(e => log('‚ùå Auto-load failed:', e.message || e));

</script>