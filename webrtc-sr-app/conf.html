<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hackathon Video Demo</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.socket.io/4.7.5/socket.io.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; }
        .video-wrapper {
            position: relative;
            width: 100%;
            padding-top: 75%; /* 4:3 Aspect Ratio */
            background-color: #1a202c;
            border-radius: 0.5rem;
        }
        .video-wrapper video, .video-wrapper canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            border-radius: 0.5rem;
        }
        #patchCanvas { z-index: 5; /* Sits on top of the video */ }
        .local-video-container {
            position: absolute;
            bottom: 1rem;
            right: 1rem;
            width: 25%;
            max-width: 200px;
            border: 2px solid white;
            border-radius: 0.5rem;
            overflow: hidden;
            z-index: 10;
        }
        /* Simple toggle switch styles */
        .switch { position: relative; display: inline-block; width: 60px; height: 34px; }
        .switch input { opacity: 0; width: 0; height: 0; }
        .slider { position: absolute; cursor: pointer; top: 0; left: 0; right: 0; bottom: 0; background-color: #4a5568; transition: .4s; border-radius: 34px; }
        .slider:before { position: absolute; content: ""; height: 26px; width: 26px; left: 4px; bottom: 4px; background-color: white; transition: .4s; border-radius: 50%; }
        input:checked + .slider { background-color: #4c51bf; }
        input:checked + .slider:before { transform: translateX(26px); }
    </style>
</head>
<body class="bg-gray-900 text-white flex items-center justify-center min-h-screen">

    <div class="w-full max-w-4xl p-4">
        <h1 class="text-3xl font-bold text-center mb-4">Video Demo w/ SR Architecture</h1>
        <p id="status" class="text-center text-gray-400 mb-6">Status: Select your role.</p>

        <!-- Role Selection -->
        <div id="role-selection" class="text-center p-4">
            <h2 class="text-xl mb-4">What is your role for Super Resolution?</h2>
            <div class="flex justify-center gap-4">
                <button id="senderButton" class="bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-6 rounded-lg text-lg">SR Sender</button>
                <button id="receiverButton" class="bg-green-600 hover:bg-green-700 text-white font-bold py-3 px-6 rounded-lg text-lg">SR Receiver</button>
            </div>
        </div>

        <div id="video-chat" class="hidden">
            <!-- Main video grid -->
            <div class="relative bg-gray-800 rounded-lg shadow-lg">
                <div class="video-wrapper">
                    <video id="remoteVideo" autoplay playsinline></video>
                    <canvas id="patchCanvas"></canvas> <!-- Canvas for patching SR frames -->
                </div>
                <div class="local-video-container">
                    <div class="video-wrapper">
                         <video id="localVideo" autoplay playsinline muted></video>
                         <canvas id="senderPatchOverlay" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; z-index: 6;"></canvas>
                    </div>
                </div>
            </div>

            <!-- Controls -->
            <div class="mt-6 bg-gray-800 p-4 rounded-lg shadow-lg">
                <h2 class="text-xl font-semibold mb-3">Controls</h2>
                <div class="flex flex-wrap items-center justify-center gap-6">
                    <div class="flex items-center gap-2">
                        <label for="bitrateInput" class="font-medium">Max Bitrate (Kbps):</label>
                        <input type="number" id="bitrateInput" class="bg-gray-700 border border-gray-600 text-white text-sm rounded-lg p-2 w-28" value="80">
                        <button id="setBitrateButton" class="bg-gray-600 hover:bg-gray-700 text-white font-bold py-2 px-4 rounded-lg">Set</button>
                    </div>
                    <div id="sr-controls" class="flex items-center gap-3">
                        <span class="font-medium">Super Resolution:</span>
                        <label class="switch">
                            <input type="checkbox" id="srToggle">
                            <span class="slider"></span>
                        </label>
                    </div>
                    <div class="flex items-center gap-2">
                        <label for="patchSizeSlider" class="font-medium">Patch Size:</label>
                        <input type="range" id="patchSizeSlider" min="200" max="600" value="413" class="bg-gray-700">
                        <span id="patchSizeValue" class="text-sm text-gray-300 w-12">413px</span>
                    </div>
                    <div class="flex items-center gap-2">
                        <label for="srFpsSlider" class="font-medium">SR FPS:</label>
                        <input type="range" id="srFpsSlider" min="0.5" max="10" value="1" step="0.5" class="bg-gray-700">
                        <span id="srFpsValue" class="text-sm text-gray-300 w-12">1.0</span>
                    </div>
                    <div class="flex items-center gap-2">
                        <label for="patchZoomSlider" class="font-medium">Patch Zoom:</label>
                        <input type="range" id="patchZoomSlider" min="0.5" max="3.0" value="1.0" step="0.1" class="bg-gray-700">
                        <span id="patchZoomValue" class="text-sm text-gray-300 w-12">1.0x</span>
                    </div>
                    <div class="flex items-center gap-3">
                        <span class="font-medium">Blocky Background:</span>
                        <label class="switch">
                            <input type="checkbox" id="blockyToggle" checked>
                            <span class="slider"></span>
                        </label>
                    </div>
                </div>
                
                <!-- Bitrate Monitoring -->
                <div class="mt-4 bg-gray-700 p-3 rounded-lg">
                    <h3 class="text-lg font-medium mb-2">📊 Bitrate Monitoring</h3>
                    <div class="grid grid-cols-2 gap-4 text-sm">
                        <div>
                            <div class="text-gray-300">Video Bitrate:</div>
                            <div id="videoBitrate" class="text-white font-mono">-- Kbps</div>
                        </div>
                        <div>
                            <div class="text-gray-300">Data Channel:</div>
                            <div id="dataBitrate" class="text-white font-mono">-- Kbps</div>
                        </div>
                        <div>
                            <div class="text-gray-300">Total Bitrate:</div>
                            <div id="totalBitrate" class="text-white font-mono">-- Kbps</div>
                        </div>
                        <div>
                            <div class="text-gray-300">SR Overhead:</div>
                            <div id="srOverhead" class="text-white font-mono">-- Kbps</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Hidden canvas for capturing frames -->
    <canvas id="captureCanvas" class="hidden"></canvas>

    <script>
        // --- CONFIGURATION ---
        const SIGNALING_SERVER_URL = 'https://e57023ff-b0b5-400b-8458-03ea0b8e6bd1-00-155a22aats1if.worf.replit.dev/';
        const FASTAPI_SERVER_URL = 'http://127.0.0.1:8000'; // Your FastAPI server
        const SR_FPS = 1; // Target FPS for Super Resolution
        
        // Check if FastAPI server is accessible
        let fastApiAvailable = false;

        // --- UI ELEMENTS ---
        const roleSelectionDiv = document.getElementById('role-selection');
        const senderButton = document.getElementById('senderButton');
        const receiverButton = document.getElementById('receiverButton');
        const bitrateInput = document.getElementById('bitrateInput');
        const setBitrateButton = document.getElementById('setBitrateButton');
        const localVideo = document.getElementById('localVideo');
        const remoteVideo = document.getElementById('remoteVideo');
        const statusDiv = document.getElementById('status');
        const videoChatContainer = document.getElementById('video-chat');
        const srControlsDiv = document.getElementById('sr-controls');
        const srToggle = document.getElementById('srToggle');
        const patchSizeSlider = document.getElementById('patchSizeSlider');
        const patchSizeValue = document.getElementById('patchSizeValue');
        const srFpsSlider = document.getElementById('srFpsSlider');
        const srFpsValue = document.getElementById('srFpsValue');
        const patchZoomSlider = document.getElementById('patchZoomSlider');
        const patchZoomValue = document.getElementById('patchZoomValue');
        const blockyToggle = document.getElementById('blockyToggle');
        const captureCanvas = document.getElementById('captureCanvas');
        
        // Bitrate monitoring elements
        const videoBitrateDiv = document.getElementById('videoBitrate');
        const dataBitrateDiv = document.getElementById('dataBitrate');
        const totalBitrateDiv = document.getElementById('totalBitrate');
        const srOverheadDiv = document.getElementById('srOverhead');
        const patchCanvas = document.getElementById('patchCanvas');
        const patchCtx = patchCanvas.getContext('2d');
        const senderPatchOverlay = document.getElementById('senderPatchOverlay');
        const senderPatchCtx = senderPatchOverlay.getContext('2d');

        // --- STATE VARIABLES ---
        let userRole = null; // 'sender' or 'receiver' for SR
        let isInitiator = false; // Am I the one starting the call?
        let localStream;
        let peerConnection;
        let videoSender;
        let dataChannel;
        let srLoopInterval = null;
        let currentPatchSize = 413; // Dynamic patch size
        let currentSRFPS = 1.0; // Dynamic SR FPS
        let currentPatchZoom = 1.0; // Dynamic patch zoom factor
        
        // Enhanced bitrate tracking variables
        let bitrateMonitorInterval = null;
        let lastVideoBytesSent = 0;
        let lastVideoBytesReceived = 0;
        let lastDataChannelBytesSent = 0;
        let lastDataChannelBytesReceived = 0;
        let srDataTransferred = 0; // Bytes transferred for SR (manual tracking)
        let lastSrBytes = 0;
        let lastTimestamp = Date.now();
        
        // SR patch persistence
        let lastSRPatch = null; // Store the last decoded SR patch
        let lastSRPatchPosition = null; // Store patch position
        let srSessionActive = false; // Track if SR is currently active
        let lastSRDataTime = 0; // Timestamp of last SR data received
        const SR_TIMEOUT = 3000; // 3 seconds timeout for SR session
        
        const socket = io(SIGNALING_SERVER_URL);
        const roomName = 'hackathon-room-sr';

        const configuration = { iceServers: [{ urls: 'stun:stun.l.google.com:19302' }] };

        // --- 1. ROLE SELECTION & INITIALIZATION ---
        senderButton.onclick = () => setUserRole('sender');
        receiverButton.onclick = () => setUserRole('receiver');
        
        // Check FastAPI server availability
        async function checkFastApiAvailability() {
            try {
                const response = await fetch(`${FASTAPI_SERVER_URL}/health`, {
                    method: 'GET',
                    signal: AbortSignal.timeout(3000) // 3 second timeout
                });
                fastApiAvailable = response.ok;
                console.log(`🔍 [FASTAPI] Server availability: ${fastApiAvailable ? 'Available' : 'Not Available'}`);
            } catch (error) {
                fastApiAvailable = false;
                console.log('🔍 [FASTAPI] Server not accessible - will disable Super Resolution features');
            }
        }
        
        // Check FastAPI on page load
        checkFastApiAvailability();

        async function setUserRole(role) {
            userRole = role;
            console.log(`[DIAGNOSTIC] SR Role selected: ${role}`);
            
            // Show/hide SR controls based on role and FastAPI availability
            if (role === 'receiver') {
                srControlsDiv.classList.add('hidden'); // Hide SR toggle for receiver
            } else if (!fastApiAvailable) {
                // Show warning for sender when FastAPI not available
                const srLabel = srControlsDiv.querySelector('span');
                srLabel.textContent = 'Super Resolution (FastAPI Not Available)';
                srToggle.disabled = true;
                srToggle.title = 'FastAPI server required for Super Resolution';
            }
            
            roleSelectionDiv.classList.add('hidden');
            statusDiv.innerText = `Role: ${role}. Enabling camera...`;
            
            try {
                localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                localVideo.srcObject = localStream;
                videoChatContainer.classList.remove('hidden');
                statusDiv.innerText = 'Camera enabled. Joining room...';
                socket.emit('join_room', roomName);
                console.log(`[DIAGNOSTIC] Emitted 'join_room' for room "${roomName}"`);
            } catch (error) {
                console.error('Error accessing media devices.', error);
                statusDiv.innerText = 'Error: Could not access camera.';
            }
        }

        // --- 2. SIMPLIFIED SIGNALING LOGIC ---
        socket.on('connect', () => console.log('[DIAGNOSTIC] Connected to signaling server.'));

        // The server tells us the room is ready and if we are the initiator
        socket.on('room_ready', (data) => {
            isInitiator = data.isInitiator;
            console.log(`[DIAGNOSTIC] 'room_ready' event received. I am ${isInitiator ? 'the initiator' : 'not the initiator'}.`);
            statusDiv.innerText = 'Peer has joined. Creating connection...';
            createPeerConnection(); // Both peers create their connection object
            if (isInitiator) {
                console.log('[DIAGNOSTIC] As initiator, I am creating an offer.');
                createOffer();
            }
        });

        socket.on('offer', async (offer) => {
            if (!isInitiator) {
                console.log('[DIAGNOSTIC] Received offer.');
                await peerConnection.setRemoteDescription(new RTCSessionDescription(offer));
                console.log('[DIAGNOSTIC] Creating answer.');
                const answer = await peerConnection.createAnswer();
                await peerConnection.setLocalDescription(answer);
                socket.emit('signal', { type: 'answer', payload: answer });
                console.log('[DIAGNOSTIC] Answer sent.');
            }
        });

        socket.on('answer', async (answer) => {
            if (isInitiator) {
                console.log('[DIAGNOSTIC] Received answer.');
                await peerConnection.setRemoteDescription(new RTCSessionDescription(answer));
            }
        });

        socket.on('candidate', (candidate) => {
            console.log('[DIAGNOSTIC] Received ICE candidate.');
            peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
        });
        
        // Generic signal handler from the server
        socket.on('signal', (message) => {
            const { type, payload } = message;
            if (type === 'offer') {
                socket.emit('forward_offer', message);
            } else if (type === 'answer') {
                socket.emit('forward_answer', message);
            } else if (type === 'candidate') {
                socket.emit('forward_candidate', message);
            }
        });


        // --- 3. WebRTC CORE LOGIC ---
        async function createOffer() {
            const offer = await peerConnection.createOffer();
            await peerConnection.setLocalDescription(offer);
            socket.emit('signal', { type: 'offer', payload: offer });
        }

        function createPeerConnection() {
            if (peerConnection) {
                console.log("[DIAGNOSTIC] Peer connection already exists. Ignoring.");
                return;
            }
            console.log('[DIAGNOSTIC] Creating new RTCPeerConnection.');
            peerConnection = new RTCPeerConnection(configuration);

            localStream.getTracks().forEach(track => {
                if (track.kind === 'video') {
                    videoSender = peerConnection.addTrack(track, localStream);
                } else {
                    peerConnection.addTrack(track, localStream);
                }
            });

            setBandwidth(); // Set initial bandwidth

            peerConnection.ontrack = (event) => {
                console.log('[DIAGNOSTIC] Remote track received.');
                remoteVideo.srcObject = event.streams[0];
                statusDiv.innerText = 'Connection established!';
                
                // Start continuous background rendering if receiver
                if (userRole === 'receiver') {
                    startBackgroundRendering();
                }
            };

            peerConnection.onicecandidate = (event) => {
                if (event.candidate) {
                    console.log('[DIAGNOSTIC] Generated ICE candidate, sending to peer.');
                    socket.emit('signal', { type: 'candidate', payload: event.candidate });
                }
            };

            // Data Channel setup - initiator creates, non-initiator receives
            if (isInitiator) {
                console.log('🔗 [DATA_CHANNEL] Creating data channel as initiator...');
                dataChannel = peerConnection.createDataChannel('latent-vectors', {
                    ordered: true,
                    maxRetransmits: 0
                });
                setupDataChannel();
                console.log('🔗 [DATA_CHANNEL] Data channel created:', dataChannel.label);
            } else {
                console.log('🔗 [DATA_CHANNEL] Waiting for data channel as non-initiator...');
                peerConnection.ondatachannel = (event) => {
                    console.log('🔗 [DATA_CHANNEL] Received data channel from peer');
                    dataChannel = event.channel;
                    setupDataChannel();
                };
            }
        }
        
        function setupDataChannel() {
            console.log('🔗 [DATA_CHANNEL] Setting up data channel for role:', userRole);
            
            dataChannel.onopen = () => {
                console.log('✅ [DATA_CHANNEL] Data channel OPEN!');
                console.log('🔍 [DATA_CHANNEL] Current state:', {
                    readyState: dataChannel.readyState,
                    label: dataChannel.label,
                    userRole: userRole,
                    isInitiator: isInitiator
                });
                
                // Start bitrate monitoring when connection is ready
                startBitrateMonitoring();
            };
            
            dataChannel.onclose = () => {
                console.log('❌ [DATA_CHANNEL] Data channel CLOSED!');
                stopBitrateMonitoring();
            };
            
            dataChannel.onerror = (error) => {
                console.error('❌ [DATA_CHANNEL] Data channel error:', error);
            };
            
            // Only the SR Receiver should listen for messages
            if (userRole === 'receiver') {
                dataChannel.onmessage = handleDataChannelMessage;
                console.log('📨 [DATA_CHANNEL] Message listener attached for receiver');
            } else {
                console.log('📡 [DATA_CHANNEL] Sender mode - no message listener needed');
            }
        }

        // --- 4. SUPER RESOLUTION & DATA CHANNEL LOGIC ---
        srToggle.onchange = () => {
            if (srToggle.checked && userRole === 'sender') {
                // Check FastAPI availability first
                if (!fastApiAvailable) {
                    statusDiv.innerText = '❌ Super Resolution requires FastAPI server connection';
                    srToggle.checked = false;
                    return;
                }
                console.log('🔍 [SR_TOGGLE] Enabling Super Resolution - Connection State:');
                console.log({
                    userRole: userRole,
                    isInitiator: isInitiator,
                    peerConnection_exists: !!peerConnection,
                    peerConnection_state: peerConnection?.connectionState,
                    peerConnection_iceState: peerConnection?.iceConnectionState,
                    dataChannel_exists: !!dataChannel,
                    dataChannel_readyState: dataChannel?.readyState,
                    dataChannel_label: dataChannel?.label
                });
                
                statusDiv.innerText = 'Super Resolution ON.';
                showSenderPatchOverlay();
                srLoopInterval = setInterval(senderSRLoop, 1000 / currentSRFPS);
                
                // Set local SR session state for sender
                srSessionActive = true;
                lastSRDataTime = Date.now();
                
                // Send SR session start message to receiver
                if (dataChannel && dataChannel.readyState === 'open') {
                    const controlMessage = {
                        type: 'sr_control',
                        action: 'start',
                        timestamp: Date.now()
                    };
                    dataChannel.send(JSON.stringify(controlMessage));
                    console.log('📡 [SR_CONTROL] Sent SR START message to receiver');
                }
                
                // Force one immediate attempt to help with debugging
                setTimeout(() => {
                    console.log('🔍 [SR_TOGGLE] Forcing immediate SR loop attempt...');
                    senderSRLoop();
                }, 100);
            } else {
                statusDiv.innerText = 'Super Resolution OFF.';
                hideSenderPatchOverlay();
                clearInterval(srLoopInterval);
                srLoopInterval = null;
                
                // Send SR session stop message to receiver
                if (dataChannel && dataChannel.readyState === 'open') {
                    const controlMessage = {
                        type: 'sr_control',
                        action: 'stop',
                        timestamp: Date.now()
                    };
                    dataChannel.send(JSON.stringify(controlMessage));
                    console.log('📡 [SR_CONTROL] Sent SR STOP message to receiver');
                }
                
                // Reset SR tracking
                srDataTransferred = 0;
                lastSrBytes = 0;
                
                // Clear stored SR patch
                lastSRPatch = null;
                lastSRPatchPosition = null;
                srSessionActive = false;
            }
        };
        
        function showSenderPatchOverlay() {
            const video = localVideo;
            const overlay = senderPatchOverlay;
            
            if (!video || !overlay) {
                console.log('⚠️ [PATCH_OVERLAY] Video or overlay element not found');
                return;
            }
            
            // Match overlay canvas to video dimensions
            overlay.width = video.clientWidth;
            overlay.height = video.clientHeight;
            
            // Draw patch indicator using SAME logic as capture
            const patchSize = currentPatchSize;
            const videoWidth = video.videoWidth || video.clientWidth;
            const videoHeight = video.videoHeight || video.clientHeight;
            
            // Use IDENTICAL coordinate calculation as capture
            const centerX = Math.floor(videoWidth / 2);
            const centerY = Math.floor(videoHeight / 2);
            const patchVideoX = centerX - patchSize / 2;
            const patchVideoY = centerY - patchSize / 2;
            
            // Scale to display coordinates
            const scaleX = overlay.width / videoWidth;
            const scaleY = overlay.height / videoHeight;
            
            const patchX = patchVideoX * scaleX;
            const patchY = patchVideoY * scaleY;
            const displayPatchWidth = patchSize * scaleX;
            const displayPatchHeight = patchSize * scaleY;
            
            senderPatchCtx.clearRect(0, 0, overlay.width, overlay.height);
            
            // Draw patch border
            senderPatchCtx.strokeStyle = '#00ff88';
            senderPatchCtx.lineWidth = 3;
            senderPatchCtx.setLineDash([10, 5]);
            senderPatchCtx.strokeRect(patchX, patchY, displayPatchWidth, displayPatchHeight);
            
            // Add label
            senderPatchCtx.fillStyle = '#00ff88';
            senderPatchCtx.font = '14px Arial';
            senderPatchCtx.textAlign = 'center';
            senderPatchCtx.fillText('SR Encoding Zone', patchX + displayPatchWidth/2, patchY - 10);
            
            console.log('📦 [PATCH_OVERLAY] Patch overlay displayed:', {
                video_coords: `(${patchVideoX}, ${patchVideoY})`,
                display_coords: `(${Math.round(patchX)}, ${Math.round(patchY)})`,
                display_size: `${Math.round(displayPatchWidth)}x${Math.round(displayPatchHeight)}`,
                video_size: `${videoWidth}x${videoHeight}`,
                canvas_size: `${video.clientWidth}x${video.clientHeight}`,
                scale: `${scaleX.toFixed(2)}x${scaleY.toFixed(2)}`
            });
        }
        
        function hideSenderPatchOverlay() {
            if (senderPatchCtx && senderPatchOverlay) {
                senderPatchCtx.clearRect(0, 0, senderPatchOverlay.width, senderPatchOverlay.height);
                console.log('📦 [PATCH_OVERLAY] Patch overlay hidden');
            }
        }

        async function senderSRLoop() {
            // Detailed data channel diagnostics
            console.log('🔍 [SENDER] Data channel status check:', {
                dataChannel_exists: !!dataChannel,
                readyState: dataChannel?.readyState || 'null',
                peerConnection_exists: !!peerConnection,
                peerConnection_state: peerConnection?.connectionState || 'null',
                userRole: userRole,
                isInitiator: isInitiator
            });
            
            if (!dataChannel) {
                console.log('⚠️ [SENDER] Data channel does not exist, skipping frame');
                return;
            }
            
            if (dataChannel.readyState !== 'open') {
                console.log(`⚠️ [SENDER] Data channel state is '${dataChannel.readyState}', not 'open'. Skipping frame.`);
                return;
            }

            // Get video dimensions
            const videoWidth = localVideo.videoWidth || localVideo.clientWidth;
            const videoHeight = localVideo.videoHeight || localVideo.clientHeight;
            
            if (videoWidth === 0 || videoHeight === 0) {
                console.log('⚠️ [SENDER] Video not ready, skipping frame');
                return;
            }
            
            // Calculate center patch coordinates (dynamic size)
            const patchSize = currentPatchSize;
            const centerX = Math.floor(videoWidth / 2);
            const centerY = Math.floor(videoHeight / 2);
            const patchX = centerX - patchSize / 2;
            const patchY = centerY - patchSize / 2;
            
            // Set up capture canvas for the patch only
            captureCanvas.width = patchSize;
            captureCanvas.height = patchSize;
            const captureCtx = captureCanvas.getContext('2d');
            
            // Draw only the center patch from the video
            captureCtx.drawImage(
                localVideo, 
                patchX, patchY, patchSize, patchSize,  // source coordinates
                0, 0, patchSize, patchSize             // destination coordinates
            );
            
            console.log('📷 [SENDER] Capturing 256x256 center patch for encoding...', {
                video_size: `${videoWidth}x${videoHeight}`,
                patch_coords: `(${patchX}, ${patchY})`,
                patch_size: `${patchSize}x${patchSize}`
            });
            
            captureCanvas.toBlob(async (blob) => {
                try {
                    const encodeStartTime = performance.now();
                    
                    const formData = new FormData();
                    formData.append('file', blob, 'frame.jpg');
                    
                    statusDiv.innerText = '🔄 Encoding frame to latent vector...';
                    
                    const response = await fetch(`${FASTAPI_SERVER_URL}/encode_latent`, {
                        method: 'POST',
                        body: formData,
                    });
                    
                    if (!response.ok) {
                        const errorText = await response.text();
                        throw new Error(`Encode error ${response.status}: ${errorText}`);
                    }
                    
                    const encodeResult = await response.json();
                    const encodeTime = performance.now() - encodeStartTime;
                    
                    console.log('✅ [SENDER] Encode successful!', {
                        encode_time_ms: encodeResult.encode_time_ms,
                        total_processing_time: Math.round(encodeTime),
                        latent_shape: encodeResult.latent_shape,
                        latent_dtype: encodeResult.latent_dtype,
                        latent_stats: encodeResult.latent_stats,
                        latent_b64_length: encodeResult.latent_b64?.length || 0,
                        serialization: 'numpy.save format (preserves metadata)',
                        patch_info: {
                            video_size: `${videoWidth}x${videoHeight}`,
                            patch_coords: `(${patchX}, ${patchY})`,
                            patch_size: `${patchSize}x${patchSize}`
                        }
                    });
                    
                    const latentMessage = {
                        latent_b64: encodeResult.latent_b64
                        // Shape and dtype are now preserved in numpy serialization
                    };
                    
                    const messageStr = JSON.stringify(latentMessage);
                    dataChannel.send(messageStr);
                    
                    // Track SR data for bitrate monitoring
                    const messageSize = messageStr.length;
                    srDataTransferred += messageSize;
                    
                    // Update sender's SR session state
                    lastSRDataTime = Date.now();
                    
                    statusDiv.innerText = `📡 Latent sent in ${Math.round(encodeTime)}ms (VAE: ${encodeResult.encode_time_ms}ms)`;
                    console.log('📡 [SENDER] Latent vector sent via data channel:', {
                        message_size_bytes: messageSize,
                        latent_b64_length: encodeResult.latent_b64?.length || 0,
                        total_sr_data_sent: srDataTransferred,
                        compression_ratio: ((encodeResult.latent_b64?.length || 0) / messageSize * 100).toFixed(1) + '%'
                    });

                } catch (error) {
                    console.error('❌ [SENDER] Error in SR loop:', error);
                    
                    // Check if it's a network/FastAPI error
                    if (error.message.includes('Failed to fetch') || error.message.includes('NetworkError')) {
                        statusDiv.innerText = '❌ FastAPI server connection lost - disabling SR';
                        fastApiAvailable = false;
                    } else {
                        statusDiv.innerText = `❌ Encode failed: ${error.message}`;
                    }
                    
                    srToggle.checked = false;
                    clearInterval(srLoopInterval);
                    hideSenderPatchOverlay();
                }
            }, 'image/jpeg');
        }

        async function handleDataChannelMessage(event) {
            const message = JSON.parse(event.data);
            
            // Handle different message types
            if (message.type === 'sr_control') {
                handleSRControlMessage(message);
                return;
            }
            
            // Handle SR latent data (legacy format without type field)
            const latentMessage = message;
            
            // Track received SR data for bitrate monitoring
            const messageSize = event.data.length;
            srDataTransferred += messageSize;
            
            // Update SR session state
            srSessionActive = true;
            lastSRDataTime = Date.now();
            
            console.log('🎯 [RECEIVER] Received latent message:', {
                latent_b64_length: latentMessage.latent_b64?.length || 0,
                message_size_bytes: messageSize,
                total_sr_data_received: srDataTransferred,
                sr_session_active: srSessionActive,
                serialization: 'numpy.save format (preserves all metadata)'
            });
            
            // Show processing indicator
            statusDiv.innerText = '🔄 Decoding latent vector...';
            
            try {
                const decodeStartTime = performance.now();
                
                const response = await fetch(`${FASTAPI_SERVER_URL}/decode_latent`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        latent_b64: latentMessage.latent_b64
                        // No longer need latent_shape or latent_dtype - numpy.save/load handles this
                    }),
                });
                
                if (!response.ok) {
                    const errorText = await response.text();
                    console.error('🔍 [RECEIVER] Decode request details:', {
                        latent_b64_sample: latentMessage.latent_b64?.substring(0, 50) + '...',
                        latent_b64_length: latentMessage.latent_b64?.length || 0,
                        serialization_format: 'numpy.save (preserves all metadata)',
                        request_body: {
                            latent_b64: latentMessage.latent_b64?.substring(0, 20) + '...'
                        }
                    });
                    throw new Error(`Decode error ${response.status}: ${errorText}`);
                }

                const decodeResult = await response.json();
                const decodeTime = performance.now() - decodeStartTime;
                
                console.log('✅ [RECEIVER] Decode successful!', {
                    decode_time_ms: decodeResult.decode_time_ms,
                    total_processing_time: Math.round(decodeTime),
                    output_size: decodeResult.output_size,
                    success: decodeResult.success
                });
                
                // Convert base64 to image and display
                const imageBlob = await fetch(`data:image/jpeg;base64,${decodeResult.image_b64}`).then(r => r.blob());
                const imageBitmap = await createImageBitmap(imageBlob);

                patchCanvas.width = remoteVideo.clientWidth;
                patchCanvas.height = remoteVideo.clientHeight;
                
                // The decoded patch is 256x256 from server - scale to current patch size
                // Calculate where to place the patch on the canvas
                const patchSize = currentPatchSize; // This is the desired display size
                
                // Position the patch at the center of the canvas (matching sender's relative position)
                const baseSize = patchSize;
                const zoomedSize = baseSize * currentPatchZoom;
                const patchCanvasX = (patchCanvas.width - zoomedSize) / 2;
                const patchCanvasY = (patchCanvas.height - zoomedSize) / 2;
                
                // Apply zoom to the patch display size
                const patchCanvasWidth = zoomedSize;
                const patchCanvasHeight = zoomedSize;
                
                console.log('🖼️ [RECEIVER] Patching decoded image:', {
                    canvas_size: `${patchCanvas.width}x${patchCanvas.height}`,
                    patch_canvas_coords: `(${Math.round(patchCanvasX)}, ${Math.round(patchCanvasY)})`,
                    patch_canvas_size: `${Math.round(patchCanvasWidth)}x${Math.round(patchCanvasHeight)}`,
                    approach: 'native 256x256 patch, centered positioning'
                });
                
                // Draw background with blocky effect if enabled
                if (blockyToggle.checked) {
                    drawBlockyBackground(patchCtx, patchCanvas.width, patchCanvas.height, patchCanvasX, patchCanvasY, patchCanvasWidth, patchCanvasHeight);
                } else {
                    // First draw the original video frame as background
                    patchCtx.drawImage(remoteVideo, 0, 0, patchCanvas.width, patchCanvas.height);
                }
                
                // Then draw the decoded patch over the specific area, scaling from 256x256 to 413px
                patchCtx.drawImage(
                    imageBitmap, 
                    0, 0, imageBitmap.width, imageBitmap.height,  // Source: full decoded image
                    patchCanvasX, patchCanvasY, patchCanvasWidth, patchCanvasHeight  // Destination: scaled to current patch size
                );
                
                // Store the SR patch for persistence
                lastSRPatch = imageBitmap;
                lastSRPatchPosition = {
                    x: patchCanvasX,
                    y: patchCanvasY,
                    width: patchCanvasWidth,
                    height: patchCanvasHeight
                };
                
                // Optional: Draw border around the patch for debugging
                patchCtx.strokeStyle = 'rgba(0, 255, 136, 0.8)';
                patchCtx.lineWidth = 2;
                patchCtx.strokeRect(patchCanvasX, patchCanvasY, patchCanvasWidth, patchCanvasHeight);
                
                // Update status with success info
                statusDiv.innerText = `✨ Patch decoded in ${Math.round(decodeTime)}ms (VAE: ${decodeResult.decode_time_ms}ms)`;
                
                console.log('🎨 [RECEIVER] Decoded patch applied to canvas at correct position');

            } catch (error) {
                console.error('❌ [RECEIVER] Error decoding/patching frame:', error);
                
                // Check if it's a network/FastAPI error
                if (error.message.includes('Failed to fetch') || error.message.includes('NetworkError')) {
                    statusDiv.innerText = '❌ FastAPI server not accessible - cannot decode SR';
                    fastApiAvailable = false;
                } else {
                    statusDiv.innerText = `❌ Decode failed: ${error.message}`;
                }
                
                // Show error visually on canvas
                patchCtx.fillStyle = 'rgba(255, 0, 0, 0.3)';
                patchCtx.fillRect(0, 0, patchCanvas.width, patchCanvas.height);
                patchCtx.fillStyle = 'white';
                patchCtx.font = '20px Arial';
                patchCtx.textAlign = 'center';
                patchCtx.fillText('Decode Error', patchCanvas.width/2, patchCanvas.height/2);
            }
        }

        // --- SR CONTROL MESSAGE HANDLING ---
        function handleSRControlMessage(message) {
            console.log('🎛️ [SR_CONTROL] Received control message:', message);
            
            if (message.action === 'start') {
                srSessionActive = true;
                lastSRDataTime = Date.now();
                statusDiv.innerText = '🔥 Super Resolution session started';
                console.log('✅ [SR_SESSION] SR session STARTED');
                
            } else if (message.action === 'stop') {
                srSessionActive = false;
                lastSRDataTime = 0;
                
                // Clear stored SR patches (but keep blocky background if enabled)
                lastSRPatch = null;
                lastSRPatchPosition = null;
                
                // Only clear canvas if blocky background is also disabled
                if (!blockyToggle.checked) {
                    clearPatchCanvas();
                }
                
                statusDiv.innerText = '❌ Super Resolution session ended';
                console.log('🔴 [SR_SESSION] SR session STOPPED - cleared SR patches');
            }
        }
        
        function clearPatchCanvas() {
            if (patchCanvas && patchCtx) {
                patchCtx.clearRect(0, 0, patchCanvas.width, patchCanvas.height);
                console.log('🧹 [PATCH_CANVAS] Canvas cleared');
            }
        }
        
        // Check for SR session timeout
        function checkSRTimeout() {
            if (srSessionActive && lastSRDataTime > 0) {
                const timeSinceLastData = Date.now() - lastSRDataTime;
                
                if (timeSinceLastData > SR_TIMEOUT) {
                    console.log(`⏰ [SR_TIMEOUT] No SR data for ${timeSinceLastData}ms, ending session`);
                    
                    // Timeout detected - end SR session
                    srSessionActive = false;
                    lastSRPatch = null;
                    lastSRPatchPosition = null;
                    
                    // Only clear canvas if blocky background is disabled
                    if (!blockyToggle.checked) {
                        clearPatchCanvas();
                    }
                    
                    if (userRole === 'receiver') {
                        statusDiv.innerText = '⏰ SR session timed out';
                    }
                }
            }
        }
        
        // Start timeout checker
        setInterval(checkSRTimeout, 1000); // Check every second

        // --- 5. BANDWIDTH THROTTLING ---
        setBitrateButton.onclick = setBandwidth;
        function setBandwidth() {
            if (!videoSender) return;
            const bitrate = parseInt(bitrateInput.value) * 1000;
            if (isNaN(bitrate) || bitrate <= 0) return;
            const parameters = videoSender.getParameters();
            if (!parameters.encodings) parameters.encodings = [{}];
            parameters.encodings[0].maxBitrate = bitrate;
            videoSender.setParameters(parameters)
                .then(() => statusDiv.innerText = `Bitrate set to ${bitrate/1000} Kbps.`)
                .catch(e => console.error('Error setting bitrate:', e));
        }

        // --- 6. PATCH SIZE CONTROL ---
        patchSizeSlider.addEventListener('input', updatePatchSize);
        
        // --- SR FPS CONTROL ---
        srFpsSlider.addEventListener('input', updateSRFPS);
        
        // --- PATCH ZOOM CONTROL ---
        patchZoomSlider.addEventListener('input', updatePatchZoom);
        
        // --- BLOCKY BACKGROUND CONTROL ---
        blockyToggle.addEventListener('change', () => {
            console.log(`🎨 [BLOCKY] Blocky background: ${blockyToggle.checked ? 'ON' : 'OFF'}`);
            
            if (!blockyToggle.checked) {
                // Clear the canvas immediately when blocky is turned off (unless SR session is active)
                if (!srSessionActive) {
                    clearPatchCanvas();
                }
            }
        });
        function updatePatchSize() {
            currentPatchSize = parseInt(patchSizeSlider.value);
            patchSizeValue.textContent = currentPatchSize + 'px';
            
            // Update sender overlay if active
            if (userRole === 'sender' && srToggle.checked) {
                showSenderPatchOverlay();
            }
        }
        
        function updateSRFPS() {
            currentSRFPS = parseFloat(srFpsSlider.value);
            srFpsValue.textContent = currentSRFPS.toFixed(1);
            
            console.log(`⚡ [SR_FPS] Updated to: ${currentSRFPS} FPS`);
            
            // Restart SR loop with new FPS if active
            if (userRole === 'sender' && srToggle.checked && srLoopInterval) {
                clearInterval(srLoopInterval);
                srLoopInterval = setInterval(senderSRLoop, 1000 / currentSRFPS);
            }
        }
        
        function updatePatchZoom() {
            currentPatchZoom = parseFloat(patchZoomSlider.value);
            patchZoomValue.textContent = currentPatchZoom.toFixed(1) + 'x';
            
            console.log(`🔍 [PATCH_ZOOM] Updated to: ${currentPatchZoom}x`);
            
            // Update stored SR patch position if we have one
            if (lastSRPatch && lastSRPatchPosition) {
                const baseSize = currentPatchSize;
                const zoomedSize = baseSize * currentPatchZoom;
                const canvasWidth = patchCanvas.width;
                const canvasHeight = patchCanvas.height;
                
                lastSRPatchPosition = {
                    x: (canvasWidth - zoomedSize) / 2,
                    y: (canvasHeight - zoomedSize) / 2,
                    width: zoomedSize,
                    height: zoomedSize
                };
            }
        }

        // --- BLOCKY BACKGROUND EFFECT ---
        function drawBlockyBackground(ctx, canvasWidth, canvasHeight, patchX, patchY, patchWidth, patchHeight) {
            // Create a temporary canvas for the blocky effect
            const tempCanvas = document.createElement('canvas');
            const tempCtx = tempCanvas.getContext('2d');
            
            // Downscale factor for blocky effect (higher = blockier)
            const scaleFactor = 16;
            tempCanvas.width = Math.max(1, Math.floor(canvasWidth / scaleFactor));
            tempCanvas.height = Math.max(1, Math.floor(canvasHeight / scaleFactor));
            
            // Draw the video to the small canvas (downscaled)
            tempCtx.drawImage(remoteVideo, 0, 0, tempCanvas.width, tempCanvas.height);
            
            // Draw the blocky version back to the main canvas (upscaled with pixelated effect)
            ctx.imageSmoothingEnabled = false; // Disable smoothing for pixelated look
            ctx.drawImage(tempCanvas, 0, 0, canvasWidth, canvasHeight);
            ctx.imageSmoothingEnabled = true; // Re-enable smoothing for other drawing operations
            
            // Optional: Draw a slightly darker overlay on the patch area to show where the high-quality patch will go
            ctx.fillStyle = 'rgba(0, 0, 0, 0.1)';
            ctx.fillRect(patchX, patchY, patchWidth, patchHeight);
        }
        
        // --- CONTINUOUS BACKGROUND RENDERING ---
        let backgroundRenderInterval = null;
        
        function startBackgroundRendering() {
            if (backgroundRenderInterval) return; // Already running
            
            backgroundRenderInterval = setInterval(() => {
                if (!remoteVideo.videoWidth || !remoteVideo.videoHeight) return;
                
                // Always render blocky background if toggle is on (regardless of SR session)
                if (blockyToggle.checked) {
                    patchCanvas.width = remoteVideo.clientWidth;
                    patchCanvas.height = remoteVideo.clientHeight;
                    
                    // Calculate patch area (even if no SR is active, show where it would be)
                    const baseSize = currentPatchSize;
                    const zoomedSize = baseSize * currentPatchZoom;
                    const patchCanvasX = (patchCanvas.width - zoomedSize) / 2;
                    const patchCanvasY = (patchCanvas.height - zoomedSize) / 2;
                    
                    drawBlockyBackground(patchCtx, patchCanvas.width, patchCanvas.height, patchCanvasX, patchCanvasY, zoomedSize, zoomedSize);
                    
                    // If we have a stored SR patch, redraw it on top of the blocky background
                    if (lastSRPatch && lastSRPatchPosition) {
                        patchCtx.drawImage(
                            lastSRPatch,
                            0, 0, lastSRPatch.width, lastSRPatch.height,
                            lastSRPatchPosition.x, lastSRPatchPosition.y, 
                            lastSRPatchPosition.width, lastSRPatchPosition.height
                        );
                        
                        // Draw border around the persisted patch
                        patchCtx.strokeStyle = 'rgba(0, 255, 136, 0.8)';
                        patchCtx.lineWidth = 2;
                        patchCtx.strokeRect(lastSRPatchPosition.x, lastSRPatchPosition.y, 
                                          lastSRPatchPosition.width, lastSRPatchPosition.height);
                    } else {
                        // Draw patch area indicator (subtle outline) if no SR patch
                        patchCtx.strokeStyle = 'rgba(0, 255, 136, 0.3)';
                        patchCtx.lineWidth = 1;
                        patchCtx.strokeRect(patchCanvasX, patchCanvasY, zoomedSize, zoomedSize);
                    }
                } else {
                    // Clear canvas when blocky toggle is off
                    clearPatchCanvas();
                }
            }, 100); // Update at ~10 FPS for smooth blocky effect
        }
        
        function stopBackgroundRendering() {
            if (backgroundRenderInterval) {
                clearInterval(backgroundRenderInterval);
                backgroundRenderInterval = null;
            }
        }

        // --- 7. ENHANCED BITRATE MONITORING ---
        function startBitrateMonitoring() {
            if (bitrateMonitorInterval) return; // Already running
            
            // Initialize timestamp
            lastTimestamp = Date.now();
            
            bitrateMonitorInterval = setInterval(async () => {
                if (!peerConnection) return;
                
                try {
                    const currentTime = Date.now();
                    const timeElapsed = (currentTime - lastTimestamp) / 1000; // seconds
                    
                    const stats = await peerConnection.getStats();
                    let videoBytesSent = 0, videoBytesReceived = 0;
                    let dataChannelBytesSent = 0, dataChannelBytesReceived = 0;
                    
                    stats.forEach(report => {
                        // Video RTP stats
                        if (report.type === 'outbound-rtp' && report.mediaType === 'video') {
                            videoBytesSent = report.bytesSent || 0;
                        } else if (report.type === 'inbound-rtp' && report.mediaType === 'video') {
                            videoBytesReceived = report.bytesReceived || 0;
                        }
                        // Data channel stats (includes SR latent data)
                        else if (report.type === 'data-channel') {
                            if (report.state === 'open') {
                                dataChannelBytesSent += report.bytesSent || 0;
                                dataChannelBytesReceived += report.bytesReceived || 0;
                            }
                        }
                    });
                    
                    // Calculate bitrates based on role
                    let videoBitrate, dataBitrate, srBitrate;
                    
                    if (userRole === 'sender') {
                        // Sender: track outgoing video + outgoing SR data
                        videoBitrate = Math.round(((videoBytesSent - lastVideoBytesSent) * 8) / (timeElapsed * 1000));
                        dataBitrate = Math.round(((dataChannelBytesSent - lastDataChannelBytesSent) * 8) / (timeElapsed * 1000));
                        srBitrate = Math.round(((srDataTransferred - lastSrBytes) * 8) / (timeElapsed * 1000));
                        
                        lastVideoBytesSent = videoBytesSent;
                        lastDataChannelBytesSent = dataChannelBytesSent;
                    } else {
                        // Receiver: track incoming video + incoming SR data
                        videoBitrate = Math.round(((videoBytesReceived - lastVideoBytesReceived) * 8) / (timeElapsed * 1000));
                        dataBitrate = Math.round(((dataChannelBytesReceived - lastDataChannelBytesReceived) * 8) / (timeElapsed * 1000));
                        srBitrate = dataBitrate; // For receiver, SR bitrate = data channel bitrate
                        
                        lastVideoBytesReceived = videoBytesReceived;
                        lastDataChannelBytesReceived = dataChannelBytesReceived;
                    }
                    
                    const totalBitrate = videoBitrate + dataBitrate;
                    
                    // Update UI with role-specific labels
                    const direction = userRole === 'sender' ? '↑' : '↓';
                    videoBitrateDiv.textContent = `${direction} ${Math.max(0, videoBitrate)} Kbps`;
                    dataBitrateDiv.textContent = `${direction} ${Math.max(0, dataBitrate)} Kbps`;
                    totalBitrateDiv.textContent = `${direction} ${Math.max(0, totalBitrate)} Kbps`;
                    srOverheadDiv.textContent = `${direction} ${Math.max(0, srBitrate)} Kbps`;
                    
                    // Store for next calculation
                    lastSrBytes = srDataTransferred;
                    lastTimestamp = currentTime;
                    
                    // Debug logging
                    console.log(`📊 [BITRATE] ${userRole.toUpperCase()}:`, {
                        video: videoBitrate + ' Kbps',
                        dataChannel: dataBitrate + ' Kbps', 
                        srOverhead: srBitrate + ' Kbps',
                        total: totalBitrate + ' Kbps',
                        srDataTransferred: srDataTransferred + ' bytes'
                    });
                    
                } catch (error) {
                    console.error('Error monitoring bitrate:', error);
                }
            }, 1000);
        }
        
        function stopBitrateMonitoring() {
            if (bitrateMonitorInterval) {
                clearInterval(bitrateMonitorInterval);
                bitrateMonitorInterval = null;
                
                // Reset tracking variables
                lastVideoBytesSent = 0;
                lastVideoBytesReceived = 0;
                lastDataChannelBytesSent = 0;
                lastDataChannelBytesReceived = 0;
                srDataTransferred = 0;
                lastSrBytes = 0;
                lastTimestamp = Date.now();
                
                // Reset display
                videoBitrateDiv.textContent = '-- Kbps';
                dataBitrateDiv.textContent = '-- Kbps';
                totalBitrateDiv.textContent = '-- Kbps';
                srOverheadDiv.textContent = '-- Kbps';
            }
        }
    </script>
</body>
</html>