<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hackathon Video Demo</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.socket.io/4.7.5/socket.io.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; }
        .video-wrapper {
            position: relative;
            width: 100%;
            padding-top: 75%; /* 4:3 Aspect Ratio */
            background-color: #1a202c;
            border-radius: 0.5rem;
        }
        .video-wrapper video, .video-wrapper canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            border-radius: 0.5rem;
        }
        #patchCanvas { z-index: 5; /* Sits on top of the video */ }
        .local-video-container {
            position: absolute;
            bottom: 1rem;
            right: 1rem;
            width: 25%;
            max-width: 200px;
            border: 2px solid white;
            border-radius: 0.5rem;
            overflow: hidden;
            z-index: 10;
        }
        /* Simple toggle switch styles */
        .switch { position: relative; display: inline-block; width: 60px; height: 34px; }
        .switch input { opacity: 0; width: 0; height: 0; }
        .slider { position: absolute; cursor: pointer; top: 0; left: 0; right: 0; bottom: 0; background-color: #4a5568; transition: .4s; border-radius: 34px; }
        .slider:before { position: absolute; content: ""; height: 26px; width: 26px; left: 4px; bottom: 4px; background-color: white; transition: .4s; border-radius: 50%; }
        input:checked + .slider { background-color: #4c51bf; }
        input:checked + .slider:before { transform: translateX(26px); }
    </style>
</head>
<body class="bg-gray-900 text-white flex items-center justify-center min-h-screen">

    <div class="w-full max-w-4xl p-4">
        <h1 class="text-3xl font-bold text-center mb-4">Video Demo w/ SR Architecture</h1>
        <p id="status" class="text-center text-gray-400 mb-6">Status: Select your role.</p>

        <!-- Role Selection -->
        <div id="role-selection" class="text-center p-4">
            <h2 class="text-xl mb-4">What is your role for Super Resolution?</h2>
            <div class="flex justify-center gap-4">
                <button id="senderButton" class="bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-6 rounded-lg text-lg">SR Sender</button>
                <button id="receiverButton" class="bg-green-600 hover:bg-green-700 text-white font-bold py-3 px-6 rounded-lg text-lg">SR Receiver</button>
            </div>
        </div>

        <div id="video-chat" class="hidden">
            <!-- Main video grid -->
            <div class="relative bg-gray-800 rounded-lg shadow-lg">
                <div class="video-wrapper">
                    <video id="remoteVideo" autoplay playsinline></video>
                    <canvas id="patchCanvas"></canvas> <!-- Canvas for patching SR frames -->
                    <canvas id="facePatchCanvas" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; z-index: 8;"></canvas> <!-- Canvas for face patches -->
                </div>
                <div class="local-video-container">
                    <div class="video-wrapper">
                         <video id="localVideo" autoplay playsinline muted></video>
                         <canvas id="senderPatchOverlay" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; z-index: 6;"></canvas>
                         <canvas id="faceDetectionCanvas" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; z-index: 7;"></canvas>
                    </div>
                </div>
            </div>

            <!-- Controls -->
            <div class="mt-6 bg-gray-800 p-4 rounded-lg shadow-lg">
                <h2 class="text-xl font-semibold mb-3">Controls</h2>
                <div class="flex flex-wrap items-center justify-center gap-6">
                    <div class="flex items-center gap-2">
                        <label for="bitrateInput" class="font-medium">Max Bitrate (Kbps):</label>
                        <input type="number" id="bitrateInput" class="bg-gray-700 border border-gray-600 text-white text-sm rounded-lg p-2 w-28" value="80">
                        <button id="setBitrateButton" class="bg-gray-600 hover:bg-gray-700 text-white font-bold py-2 px-4 rounded-lg">Set</button>
                    </div>
                    <div id="sr-controls" class="flex items-center gap-3">
                        <span class="font-medium">Super Resolution:</span>
                        <label class="switch">
                            <input type="checkbox" id="srToggle">
                            <span class="slider"></span>
                        </label>
                    </div>
                    <div class="flex items-center gap-2">
                        <label for="patchSizeSlider" class="font-medium">Patch Size:</label>
                        <input type="range" id="patchSizeSlider" min="200" max="600" value="413" class="bg-gray-700">
                        <span id="patchSizeValue" class="text-sm text-gray-300 w-12">413px</span>
                    </div>
                    <div class="flex items-center gap-2">
                        <label for="srFpsSlider" class="font-medium">SR FPS:</label>
                        <input type="range" id="srFpsSlider" min="0.5" max="10" value="1" step="0.5" class="bg-gray-700">
                        <span id="srFpsValue" class="text-sm text-gray-300 w-12">1.0</span>
                    </div>
                    <div class="flex items-center gap-2">
                        <label for="patchZoomSlider" class="font-medium">Patch Zoom:</label>
                        <input type="range" id="patchZoomSlider" min="0.5" max="3.0" value="1.0" step="0.1" class="bg-gray-700">
                        <span id="patchZoomValue" class="text-sm text-gray-300 w-12">1.0x</span>
                    </div>
                    <div class="flex items-center gap-2">
                        <label for="facePatchFpsSlider" class="font-medium">Face FPS:</label>
                        <input type="range" id="facePatchFpsSlider" min="0.1" max="2.0" value="0.5" step="0.1" class="bg-gray-700">
                        <span id="facePatchFpsValue" class="text-sm text-gray-300 w-12">0.5</span>
                    </div>
                    <div class="flex items-center gap-2">
                        <label for="faceQualitySlider" class="font-medium">Face Quality:</label>
                        <input type="range" id="faceQualitySlider" min="0.3" max="0.9" value="0.8" step="0.1" class="bg-gray-700">
                        <span id="faceQualityValue" class="text-sm text-gray-300 w-12">80%</span>
                    </div>
                    <div class="flex items-center gap-3">
                        <span class="font-medium">Blocky Background:</span>
                        <label class="switch">
                            <input type="checkbox" id="blockyToggle" checked>
                            <span class="slider"></span>
                        </label>
                    </div>
                    <div class="flex items-center gap-3">
                        <span class="font-medium">Face Detection:</span>
                        <label class="switch">
                            <input type="checkbox" id="faceDetectionToggle">
                            <span class="slider"></span>
                        </label>
                    </div>
                    <div class="flex items-center gap-3">
                        <span class="font-medium">Face Patches:</span>
                        <label class="switch">
                            <input type="checkbox" id="facePatchToggle">
                            <span class="slider"></span>
                        </label>
                    </div>
                </div>
                
                <!-- Bitrate Monitoring -->
                <div class="mt-4 bg-gray-700 p-3 rounded-lg">
                    <h3 class="text-lg font-medium mb-2">ðŸ“Š Bitrate Monitoring</h3>
                    <div class="grid grid-cols-2 gap-4 text-sm">
                        <div>
                            <div class="text-gray-300">Video Bitrate:</div>
                            <div id="videoBitrate" class="text-white font-mono">-- Kbps</div>
                        </div>
                        <div>
                            <div class="text-gray-300">Data Channel:</div>
                            <div id="dataBitrate" class="text-white font-mono">-- Kbps</div>
                        </div>
                        <div>
                            <div class="text-gray-300">Total Bitrate:</div>
                            <div id="totalBitrate" class="text-white font-mono">-- Kbps</div>
                        </div>
                        <div>
                            <div class="text-gray-300">SR Overhead:</div>
                            <div id="srOverhead" class="text-white font-mono">-- Kbps</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Hidden canvas for capturing frames -->
    <canvas id="captureCanvas" class="hidden"></canvas>

    <script>
        // --- CONFIGURATION ---
        const SIGNALING_SERVER_URL = 'https://e57023ff-b0b5-400b-8458-03ea0b8e6bd1-00-155a22aats1if.worf.replit.dev/';
        const FASTAPI_SERVER_URL = 'http://127.0.0.1:8000'; // Your FastAPI server
        const SR_FPS = 1; // Target FPS for Super Resolution
        
        // Check if FastAPI server is accessible
        let fastApiAvailable = false;

        // --- UI ELEMENTS ---
        const roleSelectionDiv = document.getElementById('role-selection');
        const senderButton = document.getElementById('senderButton');
        const receiverButton = document.getElementById('receiverButton');
        const bitrateInput = document.getElementById('bitrateInput');
        const setBitrateButton = document.getElementById('setBitrateButton');
        const localVideo = document.getElementById('localVideo');
        const remoteVideo = document.getElementById('remoteVideo');
        const statusDiv = document.getElementById('status');
        const videoChatContainer = document.getElementById('video-chat');
        const srControlsDiv = document.getElementById('sr-controls');
        const srToggle = document.getElementById('srToggle');
        const patchSizeSlider = document.getElementById('patchSizeSlider');
        const patchSizeValue = document.getElementById('patchSizeValue');
        const srFpsSlider = document.getElementById('srFpsSlider');
        const srFpsValue = document.getElementById('srFpsValue');
        const patchZoomSlider = document.getElementById('patchZoomSlider');
        const patchZoomValue = document.getElementById('patchZoomValue');
        const blockyToggle = document.getElementById('blockyToggle');
        const faceDetectionToggle = document.getElementById('faceDetectionToggle');
        const facePatchToggle = document.getElementById('facePatchToggle');
        const facePatchFpsSlider = document.getElementById('facePatchFpsSlider');
        const facePatchFpsValue = document.getElementById('facePatchFpsValue');
        const faceQualitySlider = document.getElementById('faceQualitySlider');
        const faceQualityValue = document.getElementById('faceQualityValue');
        const captureCanvas = document.getElementById('captureCanvas');
        const faceDetectionCanvas = document.getElementById('faceDetectionCanvas');
        const faceDetectionCtx = faceDetectionCanvas.getContext('2d');
        
        // Face patch canvas will be initialized lazily when needed
        
        // Bitrate monitoring elements
        const videoBitrateDiv = document.getElementById('videoBitrate');
        const dataBitrateDiv = document.getElementById('dataBitrate');
        const totalBitrateDiv = document.getElementById('totalBitrate');
        const srOverheadDiv = document.getElementById('srOverhead');
        const patchCanvas = document.getElementById('patchCanvas');
        const patchCtx = patchCanvas.getContext('2d');
        const senderPatchOverlay = document.getElementById('senderPatchOverlay');
        const senderPatchCtx = senderPatchOverlay.getContext('2d');

        // --- STATE VARIABLES ---
        let userRole = null; // 'sender' or 'receiver' for SR
        let isInitiator = false; // Am I the one starting the call?
        let localStream;
        let peerConnection;
        let videoSender;
        let dataChannel;
        let srLoopInterval = null;
        let currentPatchSize = 413; // Dynamic patch size
        let currentSRFPS = 1.0; // Dynamic SR FPS
        let currentPatchZoom = 1.0; // Dynamic patch zoom factor
        
        // Face patch variables (declare early to avoid temporal dead zone)
        let facePatchCanvas = null; // Canvas for rendering received face patches
        let facePatchCtx = null; // Context for face patch canvas
        let lastFacePatchTime = 0; // Timestamp of last face patch sent
        let facePatchFPS = 0.5; // Face patch framerate (0.5 = 1 patch every 2 seconds)
        let faceJPEGQuality = 0.8; // JPEG compression quality (0.3-0.9)
        
        // Enhanced bitrate tracking variables
        let bitrateMonitorInterval = null;
        let lastVideoBytesSent = 0;
        let lastVideoBytesReceived = 0;
        let lastDataChannelBytesSent = 0;
        let lastDataChannelBytesReceived = 0;
        let srDataTransferred = 0; // Bytes transferred for SR (manual tracking)
        let lastSrBytes = 0;
        let lastTimestamp = Date.now();
        
        // SR patch persistence
        let lastSRPatch = null; // Store the last decoded SR patch
        let lastSRPatchPosition = null; // Store patch position
        let srSessionActive = false; // Track if SR is currently active
        let lastSRDataTime = 0; // Timestamp of last SR data received
        let facePatchActive = false; // Track if face patch processing is active
        let lastFacePatch = null; // Store the last received face patch
        let lastFacePatchPosition = null; // Store face patch position
        const SR_TIMEOUT = 3000; // 3 seconds timeout for SR session
        
        // MediaPipe Face Detection variables
        let faceDetection = null;
        let faceDetectionActive = false;
        let detectedFaces = [];
        let faceDetectionInterval = null;
        
        const socket = io(SIGNALING_SERVER_URL);
        const roomName = 'hackathon-room-sr';

        const configuration = { iceServers: [{ urls: 'stun:stun.l.google.com:19302' }] };

        // --- 1. ROLE SELECTION & INITIALIZATION ---
        senderButton.onclick = () => setUserRole('sender');
        receiverButton.onclick = () => setUserRole('receiver');
        
        // Check FastAPI server availability
        async function checkFastApiAvailability() {
            try {
                const response = await fetch(`${FASTAPI_SERVER_URL}/health`, {
                    method: 'GET',
                    signal: AbortSignal.timeout(3000) // 3 second timeout
                });
                fastApiAvailable = response.ok;
                console.log(`ðŸ” [FASTAPI] Server availability: ${fastApiAvailable ? 'Available' : 'Not Available'}`);
            } catch (error) {
                fastApiAvailable = false;
                console.log('ðŸ” [FASTAPI] Server not accessible - will disable Super Resolution features');
            }
        }
        
        // Check FastAPI on page load
        checkFastApiAvailability();

        async function setUserRole(role) {
            userRole = role;
            console.log(`[DIAGNOSTIC] SR Role selected: ${role}`);
            
            // Show/hide SR controls based on role and FastAPI availability
            if (role === 'receiver') {
                srControlsDiv.classList.add('hidden'); // Hide SR toggle for receiver
            } else if (!fastApiAvailable) {
                // Show warning for sender when FastAPI not available
                const srLabel = srControlsDiv.querySelector('span');
                srLabel.textContent = 'Super Resolution (FastAPI Not Available)';
                srToggle.disabled = true;
                srToggle.title = 'FastAPI server required for Super Resolution';
            }
            
            roleSelectionDiv.classList.add('hidden');
            statusDiv.innerText = `Role: ${role}. Enabling camera...`;
            
            try {
                localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                localVideo.srcObject = localStream;
                videoChatContainer.classList.remove('hidden');
                statusDiv.innerText = 'Camera enabled. Joining room...';
                socket.emit('join_room', roomName);
                console.log(`[DIAGNOSTIC] Emitted 'join_room' for room "${roomName}"`);
            } catch (error) {
                console.error('Error accessing media devices.', error);
                statusDiv.innerText = 'Error: Could not access camera.';
            }
        }

        // --- 2. SIMPLIFIED SIGNALING LOGIC ---
        socket.on('connect', () => console.log('[DIAGNOSTIC] Connected to signaling server.'));

        // The server tells us the room is ready and if we are the initiator
        socket.on('room_ready', (data) => {
            isInitiator = data.isInitiator;
            console.log(`[DIAGNOSTIC] 'room_ready' event received. I am ${isInitiator ? 'the initiator' : 'not the initiator'}.`);
            statusDiv.innerText = 'Peer has joined. Creating connection...';
            createPeerConnection(); // Both peers create their connection object
            if (isInitiator) {
                console.log('[DIAGNOSTIC] As initiator, I am creating an offer.');
                createOffer();
            }
        });

        socket.on('offer', async (offer) => {
            if (!isInitiator) {
                console.log('[DIAGNOSTIC] Received offer.');
                await peerConnection.setRemoteDescription(new RTCSessionDescription(offer));
                console.log('[DIAGNOSTIC] Creating answer.');
                const answer = await peerConnection.createAnswer();
                await peerConnection.setLocalDescription(answer);
                socket.emit('signal', { type: 'answer', payload: answer });
                console.log('[DIAGNOSTIC] Answer sent.');
            }
        });

        socket.on('answer', async (answer) => {
            if (isInitiator) {
                console.log('[DIAGNOSTIC] Received answer.');
                await peerConnection.setRemoteDescription(new RTCSessionDescription(answer));
            }
        });

        socket.on('candidate', (candidate) => {
            console.log('[DIAGNOSTIC] Received ICE candidate.');
            peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
        });
        
        // Generic signal handler from the server
        socket.on('signal', (message) => {
            const { type, payload } = message;
            if (type === 'offer') {
                socket.emit('forward_offer', message);
            } else if (type === 'answer') {
                socket.emit('forward_answer', message);
            } else if (type === 'candidate') {
                socket.emit('forward_candidate', message);
            }
        });


        // --- 3. WebRTC CORE LOGIC ---
        async function createOffer() {
            const offer = await peerConnection.createOffer();
            await peerConnection.setLocalDescription(offer);
            socket.emit('signal', { type: 'offer', payload: offer });
        }

        function createPeerConnection() {
            if (peerConnection) {
                console.log("[DIAGNOSTIC] Peer connection already exists. Ignoring.");
                return;
            }
            console.log('[DIAGNOSTIC] Creating new RTCPeerConnection.');
            peerConnection = new RTCPeerConnection(configuration);

            localStream.getTracks().forEach(track => {
                if (track.kind === 'video') {
                    videoSender = peerConnection.addTrack(track, localStream);
                } else {
                    peerConnection.addTrack(track, localStream);
                }
            });

            setBandwidth(); // Set initial bandwidth

            peerConnection.ontrack = (event) => {
                console.log('[DIAGNOSTIC] Remote track received.');
                remoteVideo.srcObject = event.streams[0];
                statusDiv.innerText = 'Connection established!';
                
                // Start continuous background rendering if receiver
                if (userRole === 'receiver') {
                    startBackgroundRendering();
                }
            };

            peerConnection.onicecandidate = (event) => {
                if (event.candidate) {
                    console.log('[DIAGNOSTIC] Generated ICE candidate, sending to peer.');
                    socket.emit('signal', { type: 'candidate', payload: event.candidate });
                }
            };

            // Data Channel setup - initiator creates, non-initiator receives
            if (isInitiator) {
                console.log('ðŸ”— [DATA_CHANNEL] Creating data channel as initiator...');
                dataChannel = peerConnection.createDataChannel('latent-vectors', {
                    ordered: true,
                    maxRetransmits: 0
                });
                setupDataChannel();
                console.log('ðŸ”— [DATA_CHANNEL] Data channel created:', dataChannel.label);
            } else {
                console.log('ðŸ”— [DATA_CHANNEL] Waiting for data channel as non-initiator...');
                peerConnection.ondatachannel = (event) => {
                    console.log('ðŸ”— [DATA_CHANNEL] Received data channel from peer');
                    dataChannel = event.channel;
                    setupDataChannel();
                };
            }
        }
        
        function setupDataChannel() {
            console.log('ðŸ”— [DATA_CHANNEL] Setting up data channel for role:', userRole);
            
            dataChannel.onopen = () => {
                console.log('âœ… [DATA_CHANNEL] Data channel OPEN!');
                console.log('ðŸ” [DATA_CHANNEL] Current state:', {
                    readyState: dataChannel.readyState,
                    label: dataChannel.label,
                    userRole: userRole,
                    isInitiator: isInitiator
                });
                
                // Start bitrate monitoring when connection is ready
                startBitrateMonitoring();
            };
            
            dataChannel.onclose = () => {
                console.log('âŒ [DATA_CHANNEL] Data channel CLOSED!');
                stopBitrateMonitoring();
            };
            
            dataChannel.onerror = (error) => {
                console.error('âŒ [DATA_CHANNEL] Data channel error:', error);
            };
            
            // Only the SR Receiver should listen for messages
            if (userRole === 'receiver') {
                dataChannel.onmessage = handleDataChannelMessage;
                console.log('ðŸ“¨ [DATA_CHANNEL] Message listener attached for receiver');
            } else {
                console.log('ðŸ“¡ [DATA_CHANNEL] Sender mode - no message listener needed');
            }
        }

        // --- 4. SUPER RESOLUTION & DATA CHANNEL LOGIC ---
        srToggle.onchange = () => {
            if (srToggle.checked && userRole === 'sender') {
                // Check FastAPI availability first
                if (!fastApiAvailable) {
                    statusDiv.innerText = 'âŒ Super Resolution requires FastAPI server connection';
                    srToggle.checked = false;
                    return;
                }
                console.log('ðŸ” [SR_TOGGLE] Enabling Super Resolution - Connection State:');
                console.log({
                    userRole: userRole,
                    isInitiator: isInitiator,
                    peerConnection_exists: !!peerConnection,
                    peerConnection_state: peerConnection?.connectionState,
                    peerConnection_iceState: peerConnection?.iceConnectionState,
                    dataChannel_exists: !!dataChannel,
                    dataChannel_readyState: dataChannel?.readyState,
                    dataChannel_label: dataChannel?.label
                });
                
                statusDiv.innerText = 'Super Resolution ON.';
                showSenderPatchOverlay();
                srLoopInterval = setInterval(senderSRLoop, 1000 / currentSRFPS);
                
                // Set local SR session state for sender
                srSessionActive = true;
                lastSRDataTime = Date.now();
                
                // Send SR session start message to receiver
                if (dataChannel && dataChannel.readyState === 'open') {
                    const controlMessage = {
                        type: 'sr_control',
                        action: 'start',
                        timestamp: Date.now()
                    };
                    dataChannel.send(JSON.stringify(controlMessage));
                    console.log('ðŸ“¡ [SR_CONTROL] Sent SR START message to receiver');
                }
                
                // Force one immediate attempt to help with debugging
                setTimeout(() => {
                    console.log('ðŸ” [SR_TOGGLE] Forcing immediate SR loop attempt...');
                    senderSRLoop();
                }, 100);
            } else {
                statusDiv.innerText = 'Super Resolution OFF.';
                hideSenderPatchOverlay();
                clearInterval(srLoopInterval);
                srLoopInterval = null;
                
                // Send SR session stop message to receiver
                if (dataChannel && dataChannel.readyState === 'open') {
                    const controlMessage = {
                        type: 'sr_control',
                        action: 'stop',
                        timestamp: Date.now()
                    };
                    dataChannel.send(JSON.stringify(controlMessage));
                    console.log('ðŸ“¡ [SR_CONTROL] Sent SR STOP message to receiver');
                }
                
                // Reset SR tracking
                srDataTransferred = 0;
                lastSrBytes = 0;
                
                // Clear stored SR patch
                lastSRPatch = null;
                lastSRPatchPosition = null;
                srSessionActive = false;
            }
        };
        
        function showSenderPatchOverlay() {
            const video = localVideo;
            const overlay = senderPatchOverlay;
            
            if (!video || !overlay) {
                console.log('âš ï¸ [PATCH_OVERLAY] Video or overlay element not found');
                return;
            }
            
            // Match overlay canvas to video dimensions
            overlay.width = video.clientWidth;
            overlay.height = video.clientHeight;
            
            // Draw patch indicator using SAME logic as capture
            const patchSize = currentPatchSize;
            const videoWidth = video.videoWidth || video.clientWidth;
            const videoHeight = video.videoHeight || video.clientHeight;
            
            // Use IDENTICAL coordinate calculation as capture
            const centerX = Math.floor(videoWidth / 2);
            const centerY = Math.floor(videoHeight / 2);
            const patchVideoX = centerX - patchSize / 2;
            const patchVideoY = centerY - patchSize / 2;
            
            // Scale to display coordinates
            const scaleX = overlay.width / videoWidth;
            const scaleY = overlay.height / videoHeight;
            
            const patchX = patchVideoX * scaleX;
            const patchY = patchVideoY * scaleY;
            const displayPatchWidth = patchSize * scaleX;
            const displayPatchHeight = patchSize * scaleY;
            
            senderPatchCtx.clearRect(0, 0, overlay.width, overlay.height);
            
            // Draw patch border
            senderPatchCtx.strokeStyle = '#00ff88';
            senderPatchCtx.lineWidth = 3;
            senderPatchCtx.setLineDash([10, 5]);
            senderPatchCtx.strokeRect(patchX, patchY, displayPatchWidth, displayPatchHeight);
            
            // Add label
            senderPatchCtx.fillStyle = '#00ff88';
            senderPatchCtx.font = '14px Arial';
            senderPatchCtx.textAlign = 'center';
            senderPatchCtx.fillText('SR Encoding Zone', patchX + displayPatchWidth/2, patchY - 10);
            
            console.log('ðŸ“¦ [PATCH_OVERLAY] Patch overlay displayed:', {
                video_coords: `(${patchVideoX}, ${patchVideoY})`,
                display_coords: `(${Math.round(patchX)}, ${Math.round(patchY)})`,
                display_size: `${Math.round(displayPatchWidth)}x${Math.round(displayPatchHeight)}`,
                video_size: `${videoWidth}x${videoHeight}`,
                canvas_size: `${video.clientWidth}x${video.clientHeight}`,
                scale: `${scaleX.toFixed(2)}x${scaleY.toFixed(2)}`
            });
        }
        
        function hideSenderPatchOverlay() {
            if (senderPatchCtx && senderPatchOverlay) {
                senderPatchCtx.clearRect(0, 0, senderPatchOverlay.width, senderPatchOverlay.height);
                console.log('ðŸ“¦ [PATCH_OVERLAY] Patch overlay hidden');
            }
        }

        async function senderSRLoop() {
            // Detailed data channel diagnostics
            console.log('ðŸ” [SENDER] Data channel status check:', {
                dataChannel_exists: !!dataChannel,
                readyState: dataChannel?.readyState || 'null',
                peerConnection_exists: !!peerConnection,
                peerConnection_state: peerConnection?.connectionState || 'null',
                userRole: userRole,
                isInitiator: isInitiator
            });
            
            if (!dataChannel) {
                console.log('âš ï¸ [SENDER] Data channel does not exist, skipping frame');
                return;
            }
            
            if (dataChannel.readyState !== 'open') {
                console.log(`âš ï¸ [SENDER] Data channel state is '${dataChannel.readyState}', not 'open'. Skipping frame.`);
                return;
            }

            // Get video dimensions
            const videoWidth = localVideo.videoWidth || localVideo.clientWidth;
            const videoHeight = localVideo.videoHeight || localVideo.clientHeight;
            
            if (videoWidth === 0 || videoHeight === 0) {
                console.log('âš ï¸ [SENDER] Video not ready, skipping frame');
                return;
            }
            
            // Calculate center patch coordinates (dynamic size)
            const patchSize = currentPatchSize;
            const centerX = Math.floor(videoWidth / 2);
            const centerY = Math.floor(videoHeight / 2);
            const patchX = centerX - patchSize / 2;
            const patchY = centerY - patchSize / 2;
            
            // Set up capture canvas for the patch only
            captureCanvas.width = patchSize;
            captureCanvas.height = patchSize;
            const captureCtx = captureCanvas.getContext('2d');
            
            // Draw only the center patch from the video
            captureCtx.drawImage(
                localVideo, 
                patchX, patchY, patchSize, patchSize,  // source coordinates
                0, 0, patchSize, patchSize             // destination coordinates
            );
            
            console.log('ðŸ“· [SENDER] Capturing 256x256 center patch for encoding...', {
                video_size: `${videoWidth}x${videoHeight}`,
                patch_coords: `(${patchX}, ${patchY})`,
                patch_size: `${patchSize}x${patchSize}`
            });
            
            captureCanvas.toBlob(async (blob) => {
                try {
                    const encodeStartTime = performance.now();
                    
                    const formData = new FormData();
                    formData.append('file', blob, 'frame.jpg');
                    
                    statusDiv.innerText = 'ðŸ”„ Encoding frame to latent vector...';
                    
                    const response = await fetch(`${FASTAPI_SERVER_URL}/encode_latent`, {
                        method: 'POST',
                        body: formData,
                    });
                    
                    if (!response.ok) {
                        const errorText = await response.text();
                        throw new Error(`Encode error ${response.status}: ${errorText}`);
                    }
                    
                    const encodeResult = await response.json();
                    const encodeTime = performance.now() - encodeStartTime;
                    
                    console.log('âœ… [SENDER] Encode successful!', {
                        encode_time_ms: encodeResult.encode_time_ms,
                        total_processing_time: Math.round(encodeTime),
                        latent_shape: encodeResult.latent_shape,
                        latent_dtype: encodeResult.latent_dtype,
                        latent_stats: encodeResult.latent_stats,
                        latent_b64_length: encodeResult.latent_b64?.length || 0,
                        serialization: 'numpy.save format (preserves metadata)',
                        patch_info: {
                            video_size: `${videoWidth}x${videoHeight}`,
                            patch_coords: `(${patchX}, ${patchY})`,
                            patch_size: `${patchSize}x${patchSize}`
                        }
                    });
                    
                    const latentMessage = {
                        latent_b64: encodeResult.latent_b64
                        // Shape and dtype are now preserved in numpy serialization
                    };
                    
                    const messageStr = JSON.stringify(latentMessage);
                    dataChannel.send(messageStr);
                    
                    // Track SR data for bitrate monitoring
                    const messageSize = messageStr.length;
                    srDataTransferred += messageSize;
                    
                    // Update sender's SR session state
                    lastSRDataTime = Date.now();
                    
                    statusDiv.innerText = `ðŸ“¡ Latent sent in ${Math.round(encodeTime)}ms (VAE: ${encodeResult.encode_time_ms}ms)`;
                    console.log('ðŸ“¡ [SENDER] Latent vector sent via data channel:', {
                        message_size_bytes: messageSize,
                        latent_b64_length: encodeResult.latent_b64?.length || 0,
                        total_sr_data_sent: srDataTransferred,
                        compression_ratio: ((encodeResult.latent_b64?.length || 0) / messageSize * 100).toFixed(1) + '%'
                    });

                } catch (error) {
                    console.error('âŒ [SENDER] Error in SR loop:', error);
                    
                    // Check if it's a network/FastAPI error
                    if (error.message.includes('Failed to fetch') || error.message.includes('NetworkError')) {
                        statusDiv.innerText = 'âŒ FastAPI server connection lost - disabling SR';
                        fastApiAvailable = false;
                    } else {
                        statusDiv.innerText = `âŒ Encode failed: ${error.message}`;
                    }
                    
                    srToggle.checked = false;
                    clearInterval(srLoopInterval);
                    hideSenderPatchOverlay();
                }
            }, 'image/jpeg');
        }

        async function handleDataChannelMessage(event) {
            const message = JSON.parse(event.data);
            
            // Handle different message types
            if (message.type === 'sr_control') {
                handleSRControlMessage(message);
                return;
            }
            
            if (message.type === 'face_patch_control') {
                handleFacePatchControlMessage(message);
                return;
            }
            
            if (message.type === 'face_patch') {
                handleFacePatchMessage(message);
                return;
            }
            
            // Handle SR latent data (legacy format without type field)
            const latentMessage = message;
            
            // Track received SR data for bitrate monitoring
            const messageSize = event.data.length;
            srDataTransferred += messageSize;
            
            // Update SR session state
            srSessionActive = true;
            lastSRDataTime = Date.now();
            
            console.log('ðŸŽ¯ [RECEIVER] Received latent message:', {
                latent_b64_length: latentMessage.latent_b64?.length || 0,
                message_size_bytes: messageSize,
                total_sr_data_received: srDataTransferred,
                sr_session_active: srSessionActive,
                serialization: 'numpy.save format (preserves all metadata)'
            });
            
            // Show processing indicator
            statusDiv.innerText = 'ðŸ”„ Decoding latent vector...';
            
            try {
                const decodeStartTime = performance.now();
                
                const response = await fetch(`${FASTAPI_SERVER_URL}/decode_latent`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        latent_b64: latentMessage.latent_b64
                        // No longer need latent_shape or latent_dtype - numpy.save/load handles this
                    }),
                });
                
                if (!response.ok) {
                    const errorText = await response.text();
                    console.error('ðŸ” [RECEIVER] Decode request details:', {
                        latent_b64_sample: latentMessage.latent_b64?.substring(0, 50) + '...',
                        latent_b64_length: latentMessage.latent_b64?.length || 0,
                        serialization_format: 'numpy.save (preserves all metadata)',
                        request_body: {
                            latent_b64: latentMessage.latent_b64?.substring(0, 20) + '...'
                        }
                    });
                    throw new Error(`Decode error ${response.status}: ${errorText}`);
                }

                const decodeResult = await response.json();
                const decodeTime = performance.now() - decodeStartTime;
                
                console.log('âœ… [RECEIVER] Decode successful!', {
                    decode_time_ms: decodeResult.decode_time_ms,
                    total_processing_time: Math.round(decodeTime),
                    output_size: decodeResult.output_size,
                    success: decodeResult.success
                });
                
                // Convert base64 to image and display
                const imageBlob = await fetch(`data:image/jpeg;base64,${decodeResult.image_b64}`).then(r => r.blob());
                const imageBitmap = await createImageBitmap(imageBlob);

                patchCanvas.width = remoteVideo.clientWidth;
                patchCanvas.height = remoteVideo.clientHeight;
                
                // The decoded patch is 256x256 from server - scale to current patch size
                // Calculate where to place the patch on the canvas
                const patchSize = currentPatchSize; // This is the desired display size
                
                // Position the patch at the center of the canvas (matching sender's relative position)
                const baseSize = patchSize;
                const zoomedSize = baseSize * currentPatchZoom;
                const patchCanvasX = (patchCanvas.width - zoomedSize) / 2;
                const patchCanvasY = (patchCanvas.height - zoomedSize) / 2;
                
                // Apply zoom to the patch display size
                const patchCanvasWidth = zoomedSize;
                const patchCanvasHeight = zoomedSize;
                
                console.log('ðŸ–¼ï¸ [RECEIVER] Patching decoded image:', {
                    canvas_size: `${patchCanvas.width}x${patchCanvas.height}`,
                    patch_canvas_coords: `(${Math.round(patchCanvasX)}, ${Math.round(patchCanvasY)})`,
                    patch_canvas_size: `${Math.round(patchCanvasWidth)}x${Math.round(patchCanvasHeight)}`,
                    approach: 'native 256x256 patch, centered positioning'
                });
                
                // Draw background with blocky effect if enabled
                if (blockyToggle.checked) {
                    drawBlockyBackground(patchCtx, patchCanvas.width, patchCanvas.height, patchCanvasX, patchCanvasY, patchCanvasWidth, patchCanvasHeight);
                } else {
                    // First draw the original video frame as background
                    patchCtx.drawImage(remoteVideo, 0, 0, patchCanvas.width, patchCanvas.height);
                }
                
                // Then draw the decoded patch over the specific area, scaling from 256x256 to 413px
                patchCtx.drawImage(
                    imageBitmap, 
                    0, 0, imageBitmap.width, imageBitmap.height,  // Source: full decoded image
                    patchCanvasX, patchCanvasY, patchCanvasWidth, patchCanvasHeight  // Destination: scaled to current patch size
                );
                
                // Store the SR patch for persistence
                lastSRPatch = imageBitmap;
                lastSRPatchPosition = {
                    x: patchCanvasX,
                    y: patchCanvasY,
                    width: patchCanvasWidth,
                    height: patchCanvasHeight
                };
                
                // Optional: Draw border around the patch for debugging
                patchCtx.strokeStyle = 'rgba(0, 255, 136, 0.8)';
                patchCtx.lineWidth = 2;
                patchCtx.strokeRect(patchCanvasX, patchCanvasY, patchCanvasWidth, patchCanvasHeight);
                
                // Update status with success info
                statusDiv.innerText = `âœ¨ Patch decoded in ${Math.round(decodeTime)}ms (VAE: ${decodeResult.decode_time_ms}ms)`;
                
                console.log('ðŸŽ¨ [RECEIVER] Decoded patch applied to canvas at correct position');

            } catch (error) {
                console.error('âŒ [RECEIVER] Error decoding/patching frame:', error);
                
                // Check if it's a network/FastAPI error
                if (error.message.includes('Failed to fetch') || error.message.includes('NetworkError')) {
                    statusDiv.innerText = 'âŒ FastAPI server not accessible - cannot decode SR';
                    fastApiAvailable = false;
                } else {
                    statusDiv.innerText = `âŒ Decode failed: ${error.message}`;
                }
                
                // Show error visually on canvas
                patchCtx.fillStyle = 'rgba(255, 0, 0, 0.3)';
                patchCtx.fillRect(0, 0, patchCanvas.width, patchCanvas.height);
                patchCtx.fillStyle = 'white';
                patchCtx.font = '20px Arial';
                patchCtx.textAlign = 'center';
                patchCtx.fillText('Decode Error', patchCanvas.width/2, patchCanvas.height/2);
            }
        }

        // --- SR CONTROL MESSAGE HANDLING ---
        function handleSRControlMessage(message) {
            console.log('ðŸŽ›ï¸ [SR_CONTROL] Received control message:', message);
            
            if (message.action === 'start') {
                srSessionActive = true;
                lastSRDataTime = Date.now();
                statusDiv.innerText = 'ðŸ”¥ Super Resolution session started';
                console.log('âœ… [SR_SESSION] SR session STARTED');
                
            } else if (message.action === 'stop') {
                srSessionActive = false;
                lastSRDataTime = 0;
                
                // Clear stored SR patches (but keep blocky background if enabled)
                lastSRPatch = null;
                lastSRPatchPosition = null;
                
                // Only clear canvas if blocky background is also disabled
                if (!blockyToggle.checked) {
                    clearPatchCanvas();
                }
                
                statusDiv.innerText = 'âŒ Super Resolution session ended';
                console.log('ðŸ”´ [SR_SESSION] SR session STOPPED - cleared SR patches');
            }
        }
        
        function clearPatchCanvas() {
            if (patchCanvas && patchCtx) {
                patchCtx.clearRect(0, 0, patchCanvas.width, patchCanvas.height);
                console.log('ðŸ§¹ [PATCH_CANVAS] Canvas cleared');
            }
        }

        function handleFacePatchControlMessage(message) {
            console.log('ðŸŽ­ [FACE_PATCH_CONTROL] Received control message:', message);
            
            if (message.action === 'start') {
                facePatchActive = true;
                console.log('âœ… [FACE_PATCH_SESSION] Face patch session STARTED');
                
            } else if (message.action === 'stop') {
                facePatchActive = false;
                
                // Clear stored face patches
                lastFacePatch = null;
                lastFacePatchPosition = null;
                
                // Clear face patch canvas
                if (!facePatchCanvas) {
                    facePatchCanvas = document.getElementById('facePatchCanvas');
                    if (facePatchCanvas) {
                        facePatchCtx = facePatchCanvas.getContext('2d');
                    }
                }
                if (facePatchCtx) {
                    facePatchCtx.clearRect(0, 0, facePatchCanvas.width, facePatchCanvas.height);
                }
                
                console.log('ðŸ”´ [FACE_PATCH_SESSION] Face patch session STOPPED - cleared face patches');
            }
        }

        async function handleFacePatchMessage(message) {
            if (!facePatchActive) {
                console.log('âš ï¸ [FACE_PATCH] Face patches disabled, ignoring message');
                return;
            }

            // Ensure face patch canvas is initialized
            if (!facePatchCanvas) {
                facePatchCanvas = document.getElementById('facePatchCanvas');
                if (facePatchCanvas) {
                    facePatchCtx = facePatchCanvas.getContext('2d');
                } else {
                    console.error('âŒ [FACE_PATCH] Face patch canvas not found');
                    return;
                }
            }

            console.log('ðŸŽ­ [FACE_PATCH] Received face patch:', {
                face_patch_b64_length: message.face_patch_b64?.length || 0,
                original_position: message.original_position,
                patch_size: message.patch_size,
                confidence: message.confidence
            });

            try {
                // Convert base64 to image and display
                const imageBlob = await fetch(`data:image/jpeg;base64,${message.face_patch_b64}`).then(r => r.blob());
                const imageBitmap = await createImageBitmap(imageBlob);
                
                // Set up face patch canvas to match remote video
                facePatchCanvas.width = remoteVideo.clientWidth;
                facePatchCanvas.height = remoteVideo.clientHeight;
                
                // Clear previous face patches
                facePatchCtx.clearRect(0, 0, facePatchCanvas.width, facePatchCanvas.height);
                
                // Calculate face patch position on receiver canvas
                const canvasX = message.original_position.x * facePatchCanvas.width;
                const canvasY = message.original_position.y * facePatchCanvas.height;
                const canvasWidth = message.original_position.width * facePatchCanvas.width;
                const canvasHeight = message.original_position.height * facePatchCanvas.height;
                
                // Draw the face patch at the original position
                facePatchCtx.drawImage(
                    imageBitmap,
                    canvasX, canvasY, canvasWidth, canvasHeight
                );
                
                // Store for persistence
                lastFacePatch = imageBitmap;
                lastFacePatchPosition = {
                    x: canvasX,
                    y: canvasY,
                    width: canvasWidth,
                    height: canvasHeight
                };
                
                console.log(`âœ… [FACE_PATCH] Displayed face patch at (${canvasX.toFixed(0)}, ${canvasY.toFixed(0)}) size ${canvasWidth.toFixed(0)}x${canvasHeight.toFixed(0)}`);
                
            } catch (error) {
                console.error('âŒ [FACE_PATCH] Error displaying face patch:', error);
            }
        }
        
        // Check for SR session timeout
        function checkSRTimeout() {
            if (srSessionActive && lastSRDataTime > 0) {
                const timeSinceLastData = Date.now() - lastSRDataTime;
                
                if (timeSinceLastData > SR_TIMEOUT) {
                    console.log(`â° [SR_TIMEOUT] No SR data for ${timeSinceLastData}ms, ending session`);
                    
                    // Timeout detected - end SR session
                    srSessionActive = false;
                    lastSRPatch = null;
                    lastSRPatchPosition = null;
                    
                    // Only clear canvas if blocky background is disabled
                    if (!blockyToggle.checked) {
                        clearPatchCanvas();
                    }
                    
                    if (userRole === 'receiver') {
                        statusDiv.innerText = 'â° SR session timed out';
                    }
                }
            }
        }
        
        // Start timeout checker
        setInterval(checkSRTimeout, 1000); // Check every second

        // --- MEDIAPIPE FACE DETECTION ---
        function initializeFaceDetection() {
            if (typeof FaceDetection === 'undefined') {
                console.warn('âš ï¸ [FACE_DETECTION] MediaPipe not available');
                return;
            }

            faceDetection = new FaceDetection({
                locateFile: (file) => {
                    return `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`;
                }
            });

            faceDetection.setOptions({
                model: 'short',
                minDetectionConfidence: 0.5,
            });

            faceDetection.onResults(onFaceDetectionResults);
            console.log('âœ… [FACE_DETECTION] MediaPipe initialized');
        }

        function onFaceDetectionResults(results) {
            detectedFaces = results.detections || [];
            
            if (faceDetectionActive) {
                drawFaceDetectionOverlay();
                
                // Process face patches if we have faces and are in sender mode
                if (detectedFaces.length > 0 && userRole === 'sender' && facePatchActive) {
                    processFacePatches();
                }
            }
        }

        function drawFaceDetectionOverlay() {
            // Match canvas size to video
            faceDetectionCanvas.width = localVideo.clientWidth;
            faceDetectionCanvas.height = localVideo.clientHeight;
            
            // Clear previous drawings
            faceDetectionCtx.clearRect(0, 0, faceDetectionCanvas.width, faceDetectionCanvas.height);
            
            if (detectedFaces.length > 0) {
                const videoWidth = localVideo.videoWidth || localVideo.clientWidth;
                const videoHeight = localVideo.videoHeight || localVideo.clientHeight;
                
                detectedFaces.forEach((detection, index) => {
                    const bbox = detection.boundingBox;
                    
                    // Convert normalized coordinates to canvas coordinates
                    const x = bbox.xCenter * faceDetectionCanvas.width - (bbox.width * faceDetectionCanvas.width) / 2;
                    const y = bbox.yCenter * faceDetectionCanvas.height - (bbox.height * faceDetectionCanvas.height) / 2;
                    const width = bbox.width * faceDetectionCanvas.width;
                    const height = bbox.height * faceDetectionCanvas.height;
                    
                    // Draw bounding box
                    faceDetectionCtx.strokeStyle = '#00ff88';
                    faceDetectionCtx.lineWidth = 3;
                    faceDetectionCtx.strokeRect(x, y, width, height);
                    
                    // Draw label
                    faceDetectionCtx.fillStyle = '#00ff88';
                    faceDetectionCtx.font = '16px Arial';
                    faceDetectionCtx.fillText(`Face ${index + 1} (${(detection.score * 100).toFixed(0)}%)`, 
                                             x, y - 10);
                    
                    console.log(`ðŸ‘¤ [FACE_DETECTED] Face ${index + 1} at (${x.toFixed(0)}, ${y.toFixed(0)}) size ${width.toFixed(0)}x${height.toFixed(0)}`);
                });
            }
        }

        async function startFaceDetection() {
            if (!faceDetection) {
                initializeFaceDetection();
                
                // Wait a moment for initialization
                await new Promise(resolve => setTimeout(resolve, 1000));
            }
            
            if (!faceDetection) {
                console.error('âŒ [FACE_DETECTION] Failed to initialize MediaPipe');
                return;
            }
            
            faceDetectionActive = true;
            
            // Create a temporary canvas for MediaPipe processing
            const tempCanvas = document.createElement('canvas');
            const tempCtx = tempCanvas.getContext('2d');
            
            faceDetectionInterval = setInterval(async () => {
                if (!faceDetectionActive || !localVideo.videoWidth || !localVideo.videoHeight) return;
                
                try {
                    // Set canvas size to video dimensions
                    tempCanvas.width = localVideo.videoWidth;
                    tempCanvas.height = localVideo.videoHeight;
                    
                    // Draw the video frame to the canvas
                    tempCtx.drawImage(localVideo, 0, 0, localVideo.videoWidth, localVideo.videoHeight);
                    
                    // Send the canvas to MediaPipe instead of the video element
                    await faceDetection.send({ image: tempCanvas });
                } catch (error) {
                    console.error('âŒ [FACE_DETECTION] Processing error:', error);
                }
            }, 100); // Process at ~10 FPS
            
            console.log('ðŸ” [FACE_DETECTION] Started');
        }

        function stopFaceDetection() {
            faceDetectionActive = false;
            
            if (faceDetectionInterval) {
                clearInterval(faceDetectionInterval);
                faceDetectionInterval = null;
            }
            
            // Clear the overlay
            faceDetectionCtx.clearRect(0, 0, faceDetectionCanvas.width, faceDetectionCanvas.height);
            detectedFaces = [];
            
            console.log('ðŸ” [FACE_DETECTION] Stopped');
        }

        async function processFacePatches() {
            if (!dataChannel || dataChannel.readyState !== 'open') {
                console.log('âš ï¸ [FACE_PATCH] Data channel not available, skipping face patch processing');
                return;
            }
            
            if (detectedFaces.length === 0) return;
            
            // Throttle face patch framerate to reduce bandwidth
            const now = Date.now();
            const timeSinceLastPatch = now - lastFacePatchTime;
            const minInterval = 1000 / facePatchFPS; // Convert FPS to milliseconds
            
            if (timeSinceLastPatch < minInterval) {
                return; // Skip this frame
            }
            
            lastFacePatchTime = now;
            
            // Get video dimensions
            const videoWidth = localVideo.videoWidth || localVideo.clientWidth;
            const videoHeight = localVideo.videoHeight || localVideo.clientHeight;
            
            if (videoWidth === 0 || videoHeight === 0) {
                console.log('âš ï¸ [FACE_PATCH] Video not ready, skipping face patch processing');
                return;
            }
            
            // Process the first detected face
            const detection = detectedFaces[0];
            const bbox = detection.boundingBox;
            
            // Convert normalized coordinates to video coordinates
            const faceX = (bbox.xCenter - bbox.width / 2) * videoWidth;
            const faceY = (bbox.yCenter - bbox.height / 2) * videoHeight;
            const faceWidth = bbox.width * videoWidth;
            const faceHeight = bbox.height * videoHeight;
            
            // Add padding around face (20% larger)
            const padding = 0.2;
            const paddedWidth = faceWidth * (1 + padding);
            const paddedHeight = faceHeight * (1 + padding);
            const paddedX = faceX - (paddedWidth - faceWidth) / 2;
            const paddedY = faceY - (paddedHeight - faceHeight) / 2;
            
            // Ensure coordinates are within video bounds
            const clampedX = Math.max(0, Math.min(paddedX, videoWidth - paddedWidth));
            const clampedY = Math.max(0, Math.min(paddedY, videoHeight - paddedHeight));
            const clampedWidth = Math.min(paddedWidth, videoWidth - clampedX);
            const clampedHeight = Math.min(paddedHeight, videoHeight - clampedY);
            
            try {
                // Create temporary canvas for extracting face patch
                const tempCanvas = document.createElement('canvas');
                const tempCtx = tempCanvas.getContext('2d');
                
                // Set patch size (similar to SR patches, use 256x256 for consistency)
                const patchSize = 256;
                tempCanvas.width = patchSize;
                tempCanvas.height = patchSize;
                
                // Draw the face region to the canvas, scaling to fit patch size
                tempCtx.drawImage(
                    localVideo,
                    clampedX, clampedY, clampedWidth, clampedHeight,  // source rectangle
                    0, 0, patchSize, patchSize                        // destination rectangle
                );
                
                // Convert to JPEG (with dynamic compression quality)
                const jpegDataUrl = tempCanvas.toDataURL('image/jpeg', faceJPEGQuality);
                const jpegBase64 = jpegDataUrl.split(',')[1]; // Remove data URL prefix
                
                // Create face patch message
                const facePatchMessage = {
                    type: 'face_patch',
                    face_patch_b64: jpegBase64,
                    original_position: {
                        x: clampedX / videoWidth,        // normalized coordinates
                        y: clampedY / videoHeight,
                        width: clampedWidth / videoWidth,
                        height: clampedHeight / videoHeight
                    },
                    patch_size: patchSize,
                    timestamp: Date.now(),
                    confidence: detection.score
                };
                
                // Send via data channel
                const messageStr = JSON.stringify(facePatchMessage);
                dataChannel.send(messageStr);
                
                console.log(`ðŸŽ­ [FACE_PATCH] Sent face patch: ${clampedWidth.toFixed(0)}x${clampedHeight.toFixed(0)} at (${clampedX.toFixed(0)}, ${clampedY.toFixed(0)}) confidence: ${(detection.score * 100).toFixed(0)}%`);
                
            } catch (error) {
                console.error('âŒ [FACE_PATCH] Error processing face patch:', error);
            }
        }

        // --- 5. BANDWIDTH THROTTLING ---
        setBitrateButton.onclick = setBandwidth;
        function setBandwidth() {
            if (!videoSender) return;
            const bitrate = parseInt(bitrateInput.value) * 1000;
            if (isNaN(bitrate) || bitrate <= 0) return;
            const parameters = videoSender.getParameters();
            if (!parameters.encodings) parameters.encodings = [{}];
            parameters.encodings[0].maxBitrate = bitrate;
            videoSender.setParameters(parameters)
                .then(() => statusDiv.innerText = `Bitrate set to ${bitrate/1000} Kbps.`)
                .catch(e => console.error('Error setting bitrate:', e));
        }

        // --- 6. PATCH SIZE CONTROL ---
        patchSizeSlider.addEventListener('input', updatePatchSize);
        
        // --- SR FPS CONTROL ---
        srFpsSlider.addEventListener('input', updateSRFPS);
        
        // --- PATCH ZOOM CONTROL ---
        patchZoomSlider.addEventListener('input', updatePatchZoom);
        
        // --- FACE PATCH FPS CONTROL ---
        facePatchFpsSlider.addEventListener('input', updateFacePatchFPS);
        
        // --- FACE JPEG QUALITY CONTROL ---
        faceQualitySlider.addEventListener('input', updateFaceQuality);
        
        // --- BLOCKY BACKGROUND CONTROL ---
        blockyToggle.addEventListener('change', () => {
            console.log(`ðŸŽ¨ [BLOCKY] Blocky background: ${blockyToggle.checked ? 'ON' : 'OFF'}`);
            
            if (!blockyToggle.checked) {
                // Clear the canvas immediately when blocky is turned off (unless SR session is active)
                if (!srSessionActive) {
                    clearPatchCanvas();
                }
            }
        });
        
        // --- FACE DETECTION CONTROL ---
        faceDetectionToggle.addEventListener('change', () => {
            console.log(`ðŸ‘¤ [FACE_DETECTION] Face detection: ${faceDetectionToggle.checked ? 'ON' : 'OFF'}`);
            
            if (faceDetectionToggle.checked) {
                startFaceDetection();
            } else {
                stopFaceDetection();
            }
        });
        
        // --- FACE PATCH CONTROL ---
        facePatchToggle.addEventListener('change', () => {
            console.log(`ðŸŽ­ [FACE_PATCH] Face patches: ${facePatchToggle.checked ? 'ON' : 'OFF'}`);
            
            facePatchActive = facePatchToggle.checked;
            
            if (!facePatchActive) {
                // Clear face patches when turned off
                if (!facePatchCanvas) {
                    facePatchCanvas = document.getElementById('facePatchCanvas');
                    if (facePatchCanvas) {
                        facePatchCtx = facePatchCanvas.getContext('2d');
                    }
                }
                if (facePatchCtx) {
                    facePatchCtx.clearRect(0, 0, facePatchCanvas.width, facePatchCanvas.height);
                }
                lastFacePatch = null;
                lastFacePatchPosition = null;
                
                // Send control message to stop face patches
                if (dataChannel && dataChannel.readyState === 'open') {
                    const controlMessage = {
                        type: 'face_patch_control',
                        action: 'stop',
                        timestamp: Date.now()
                    };
                    dataChannel.send(JSON.stringify(controlMessage));
                }
            } else {
                // Send control message to start face patches
                if (dataChannel && dataChannel.readyState === 'open') {
                    const controlMessage = {
                        type: 'face_patch_control',
                        action: 'start',
                        timestamp: Date.now()
                    };
                    dataChannel.send(JSON.stringify(controlMessage));
                }
            }
        });
        function updatePatchSize() {
            currentPatchSize = parseInt(patchSizeSlider.value);
            patchSizeValue.textContent = currentPatchSize + 'px';
            
            // Update sender overlay if active
            if (userRole === 'sender' && srToggle.checked) {
                showSenderPatchOverlay();
            }
        }
        
        function updateSRFPS() {
            currentSRFPS = parseFloat(srFpsSlider.value);
            srFpsValue.textContent = currentSRFPS.toFixed(1);
            
            console.log(`âš¡ [SR_FPS] Updated to: ${currentSRFPS} FPS`);
            
            // Restart SR loop with new FPS if active
            if (userRole === 'sender' && srToggle.checked && srLoopInterval) {
                clearInterval(srLoopInterval);
                srLoopInterval = setInterval(senderSRLoop, 1000 / currentSRFPS);
            }
        }
        
        function updatePatchZoom() {
            currentPatchZoom = parseFloat(patchZoomSlider.value);
            patchZoomValue.textContent = currentPatchZoom.toFixed(1) + 'x';
            
            console.log(`ðŸ” [PATCH_ZOOM] Updated to: ${currentPatchZoom}x`);
            
            // Update stored SR patch position if we have one
            if (lastSRPatch && lastSRPatchPosition) {
                const baseSize = currentPatchSize;
                const zoomedSize = baseSize * currentPatchZoom;
                const canvasWidth = patchCanvas.width;
                const canvasHeight = patchCanvas.height;
                
                lastSRPatchPosition = {
                    x: (canvasWidth - zoomedSize) / 2,
                    y: (canvasHeight - zoomedSize) / 2,
                    width: zoomedSize,
                    height: zoomedSize
                };
            }
        }
        
        function updateFacePatchFPS() {
            facePatchFPS = parseFloat(facePatchFpsSlider.value);
            facePatchFpsValue.textContent = facePatchFPS.toFixed(1);
            
            console.log(`ðŸŽ­ [FACE_PATCH_FPS] Updated to: ${facePatchFPS} FPS`);
        }
        
        function updateFaceQuality() {
            faceJPEGQuality = parseFloat(faceQualitySlider.value);
            const percentage = Math.round(faceJPEGQuality * 100);
            faceQualityValue.textContent = percentage + '%';
            
            console.log(`ðŸ“¸ [FACE_QUALITY] Updated to: ${percentage}% (${faceJPEGQuality})`);
        }

        // --- BLOCKY BACKGROUND EFFECT ---
        function drawBlockyBackground(ctx, canvasWidth, canvasHeight, patchX, patchY, patchWidth, patchHeight) {
            // Create a temporary canvas for the blocky effect
            const tempCanvas = document.createElement('canvas');
            const tempCtx = tempCanvas.getContext('2d');
            
            // Downscale factor for blocky effect (higher = blockier)
            const scaleFactor = 16;
            tempCanvas.width = Math.max(1, Math.floor(canvasWidth / scaleFactor));
            tempCanvas.height = Math.max(1, Math.floor(canvasHeight / scaleFactor));
            
            // Draw the video to the small canvas (downscaled)
            tempCtx.drawImage(remoteVideo, 0, 0, tempCanvas.width, tempCanvas.height);
            
            // Draw the blocky version back to the main canvas (upscaled with pixelated effect)
            ctx.imageSmoothingEnabled = false; // Disable smoothing for pixelated look
            ctx.drawImage(tempCanvas, 0, 0, canvasWidth, canvasHeight);
            ctx.imageSmoothingEnabled = true; // Re-enable smoothing for other drawing operations
            
            // Optional: Draw a slightly darker overlay on the patch area to show where the high-quality patch will go
            ctx.fillStyle = 'rgba(0, 0, 0, 0.1)';
            ctx.fillRect(patchX, patchY, patchWidth, patchHeight);
        }
        
        // --- CONTINUOUS BACKGROUND RENDERING ---
        let backgroundRenderInterval = null;
        
        function startBackgroundRendering() {
            if (backgroundRenderInterval) return; // Already running
            
            backgroundRenderInterval = setInterval(() => {
                if (!remoteVideo.videoWidth || !remoteVideo.videoHeight) return;
                
                // Always render blocky background if toggle is on (regardless of SR session)
                if (blockyToggle.checked) {
                    patchCanvas.width = remoteVideo.clientWidth;
                    patchCanvas.height = remoteVideo.clientHeight;
                    
                    // Calculate patch area (even if no SR is active, show where it would be)
                    const baseSize = currentPatchSize;
                    const zoomedSize = baseSize * currentPatchZoom;
                    const patchCanvasX = (patchCanvas.width - zoomedSize) / 2;
                    const patchCanvasY = (patchCanvas.height - zoomedSize) / 2;
                    
                    drawBlockyBackground(patchCtx, patchCanvas.width, patchCanvas.height, patchCanvasX, patchCanvasY, zoomedSize, zoomedSize);
                    
                    // If we have a stored SR patch, redraw it on top of the blocky background
                    if (lastSRPatch && lastSRPatchPosition) {
                        patchCtx.drawImage(
                            lastSRPatch,
                            0, 0, lastSRPatch.width, lastSRPatch.height,
                            lastSRPatchPosition.x, lastSRPatchPosition.y, 
                            lastSRPatchPosition.width, lastSRPatchPosition.height
                        );
                        
                        // Draw border around the persisted patch
                        patchCtx.strokeStyle = 'rgba(0, 255, 136, 0.8)';
                        patchCtx.lineWidth = 2;
                        patchCtx.strokeRect(lastSRPatchPosition.x, lastSRPatchPosition.y, 
                                          lastSRPatchPosition.width, lastSRPatchPosition.height);
                    } else {
                        // Draw patch area indicator (subtle outline) if no SR patch
                        patchCtx.strokeStyle = 'rgba(0, 255, 136, 0.3)';
                        patchCtx.lineWidth = 1;
                        patchCtx.strokeRect(patchCanvasX, patchCanvasY, zoomedSize, zoomedSize);
                    }
                } else {
                    // Clear canvas when blocky toggle is off
                    clearPatchCanvas();
                }
            }, 100); // Update at ~10 FPS for smooth blocky effect
        }
        
        function stopBackgroundRendering() {
            if (backgroundRenderInterval) {
                clearInterval(backgroundRenderInterval);
                backgroundRenderInterval = null;
            }
        }

        // --- 7. ENHANCED BITRATE MONITORING ---
        function startBitrateMonitoring() {
            if (bitrateMonitorInterval) return; // Already running
            
            // Initialize timestamp
            lastTimestamp = Date.now();
            
            bitrateMonitorInterval = setInterval(async () => {
                if (!peerConnection) return;
                
                try {
                    const currentTime = Date.now();
                    const timeElapsed = (currentTime - lastTimestamp) / 1000; // seconds
                    
                    const stats = await peerConnection.getStats();
                    let videoBytesSent = 0, videoBytesReceived = 0;
                    let dataChannelBytesSent = 0, dataChannelBytesReceived = 0;
                    
                    stats.forEach(report => {
                        // Video RTP stats
                        if (report.type === 'outbound-rtp' && report.mediaType === 'video') {
                            videoBytesSent = report.bytesSent || 0;
                        } else if (report.type === 'inbound-rtp' && report.mediaType === 'video') {
                            videoBytesReceived = report.bytesReceived || 0;
                        }
                        // Data channel stats (includes SR latent data)
                        else if (report.type === 'data-channel') {
                            if (report.state === 'open') {
                                dataChannelBytesSent += report.bytesSent || 0;
                                dataChannelBytesReceived += report.bytesReceived || 0;
                            }
                        }
                    });
                    
                    // Calculate bitrates based on role
                    let videoBitrate, dataBitrate, srBitrate;
                    
                    if (userRole === 'sender') {
                        // Sender: track outgoing video + outgoing SR data
                        videoBitrate = Math.round(((videoBytesSent - lastVideoBytesSent) * 8) / (timeElapsed * 1000));
                        dataBitrate = Math.round(((dataChannelBytesSent - lastDataChannelBytesSent) * 8) / (timeElapsed * 1000));
                        srBitrate = Math.round(((srDataTransferred - lastSrBytes) * 8) / (timeElapsed * 1000));
                        
                        lastVideoBytesSent = videoBytesSent;
                        lastDataChannelBytesSent = dataChannelBytesSent;
                    } else {
                        // Receiver: track incoming video + incoming SR data
                        videoBitrate = Math.round(((videoBytesReceived - lastVideoBytesReceived) * 8) / (timeElapsed * 1000));
                        dataBitrate = Math.round(((dataChannelBytesReceived - lastDataChannelBytesReceived) * 8) / (timeElapsed * 1000));
                        srBitrate = dataBitrate; // For receiver, SR bitrate = data channel bitrate
                        
                        lastVideoBytesReceived = videoBytesReceived;
                        lastDataChannelBytesReceived = dataChannelBytesReceived;
                    }
                    
                    const totalBitrate = videoBitrate + dataBitrate;
                    
                    // Update UI with role-specific labels
                    const direction = userRole === 'sender' ? 'â†‘' : 'â†“';
                    videoBitrateDiv.textContent = `${direction} ${Math.max(0, videoBitrate)} Kbps`;
                    dataBitrateDiv.textContent = `${direction} ${Math.max(0, dataBitrate)} Kbps`;
                    totalBitrateDiv.textContent = `${direction} ${Math.max(0, totalBitrate)} Kbps`;
                    srOverheadDiv.textContent = `${direction} ${Math.max(0, srBitrate)} Kbps`;
                    
                    // Store for next calculation
                    lastSrBytes = srDataTransferred;
                    lastTimestamp = currentTime;
                    
                    // Debug logging
                    console.log(`ðŸ“Š [BITRATE] ${userRole.toUpperCase()}:`, {
                        video: videoBitrate + ' Kbps',
                        dataChannel: dataBitrate + ' Kbps', 
                        srOverhead: srBitrate + ' Kbps',
                        total: totalBitrate + ' Kbps',
                        srDataTransferred: srDataTransferred + ' bytes'
                    });
                    
                } catch (error) {
                    console.error('Error monitoring bitrate:', error);
                }
            }, 1000);
        }
        
        function stopBitrateMonitoring() {
            if (bitrateMonitorInterval) {
                clearInterval(bitrateMonitorInterval);
                bitrateMonitorInterval = null;
                
                // Reset tracking variables
                lastVideoBytesSent = 0;
                lastVideoBytesReceived = 0;
                lastDataChannelBytesSent = 0;
                lastDataChannelBytesReceived = 0;
                srDataTransferred = 0;
                lastSrBytes = 0;
                lastTimestamp = Date.now();
                
                // Reset display
                videoBitrateDiv.textContent = '-- Kbps';
                dataBitrateDiv.textContent = '-- Kbps';
                totalBitrateDiv.textContent = '-- Kbps';
                srOverheadDiv.textContent = '-- Kbps';
            }
        }
    </script>
</body>
</html>